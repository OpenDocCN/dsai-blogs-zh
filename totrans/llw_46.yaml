- en: An Overview of Deep Learning for Curious People
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://lilianweng.github.io/posts/2017-06-21-overview/](https://lilianweng.github.io/posts/2017-06-21-overview/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: (The post was originated from my talk for [WiMLDS x Fintech meetup](http://wimlds.org/chapters/about-bay-area/)
    hosted by [Affirm](www.affirm.com).)
  prefs: []
  type: TYPE_NORMAL
- en: I believe many of you have watched or heard of the [games](https://youtu.be/vFr3K2DORc8)
    between AlphaGo and professional Go player [Lee Sedol](https://en.wikipedia.org/wiki/Lee_Sedol)
    in 2016\. Lee has the highest rank of nine dan and many world championships. No
    doubt, he is one of the best Go players in the world, but he [lost by 1-4](https://www.scientificamerican.com/article/how-the-computer-beat-the-go-master/)
    in this series versus AlphaGo. Before this, Go was considered to be an intractable
    game for computers to master, as its simple rules lay out an exponential number
    of variations in the board positions, many more than what in Chess. This event
    surely highlighted 2016 as a big year for AI. Because of AlphaGo, much attention
    has been attracted to the progress of AI.
  prefs: []
  type: TYPE_NORMAL
- en: Meanwhile, many companies are spending resources on pushing the edges of AI
    applications, that indeed have the potential to change or even revolutionize how
    we are gonna live. Familiar examples include self-driving cars, chatbots, home
    assistant devices and many others. One of the secret receipts behind the progress
    we have had in recent years is deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: Why Does Deep Learning Work Now?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Deep learning models, in simple words, are large and deep artificial neural
    nets. A neural network (“NN”) can be well presented in a [directed acyclic graph](https://en.wikipedia.org/wiki/Directed_acyclic_graph):
    the input layer takes in signal vectors; one or multiple hidden layers process
    the outputs of the previous layer. The initial concept of a neural network can
    be traced back to more than [half a century ago](https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/History/history1.html).
    But why does it work now? Why do people start talking about them all of a sudden?'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/6395341b1b48fca87b40a0024e698d45.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Fig. 1\. A three-layer artificial neural network. (Image source: [http://cs231n.github.io/convolutional-networks/#conv](http://cs231n.github.io/convolutional-networks/#conv))'
  prefs: []
  type: TYPE_NORMAL
- en: 'The reason is surprisingly simple:'
  prefs: []
  type: TYPE_NORMAL
- en: We have a lot **more data**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have **much powerful computers**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A large and deep neural network has many more layers + many more nodes in each
    layer, which results in exponentially many more parameters to tune. Without enough
    data, we cannot learn parameters efficiently. Without powerful computers, learning
    would be too slow and insufficient.
  prefs: []
  type: TYPE_NORMAL
- en: Here is an interesting plot presenting the relationship between the data scale
    and the model performance, proposed by Andrew Ng in his “[Nuts and Bolts of Applying
    Deep Learning](https://youtu.be/F1ka6a13S9I)” talk. On a small dataset, traditional
    algorithms (Regression, Random Forests, SVM, GBM, etc.) or statistical learning
    does a great job, but once the data scale goes up to the sky, the large NN outperforms
    others. Partially because compared to a traditional ML model, a neural network
    model has many more parameters and has the capability to learn complicated nonlinear
    patterns. Thus we expect the model to pick the most helpful features by itself
    without too much expert-involved manual feature engineering.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/deb8f2d4b8ceab0b159fe0c0196f4316.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Fig. 2\. The data scale versus the model performance. (Recreated based on:
    [https://youtu.be/F1ka6a13S9I](https://youtu.be/F1ka6a13S9I))'
  prefs: []
  type: TYPE_NORMAL
- en: Deep Learning Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Next, let’s go through a few classical deep learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional Neural Network
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Convolutional neural networks, short for “CNN”, is a type of feed-forward artificial
    neural networks, in which the connectivity pattern between its neurons is inspired
    by the organization of the visual cortex system. The primary visual cortex (V1)
    does edge detection out of the raw visual input from the retina. The secondary
    visual cortex (V2), also called prestriate cortex, receives the edge features
    from V1 and extracts simple visual properties such as orientation, spatial frequency,
    and color. The visual area V4 handles more complicated object attributes. All
    the processed visual features flow into the final logic unit, inferior temporal
    gyrus (IT), for object recognition. The shortcut between V1 and V4 inspires a
    special type of CNN with connections between non-adjacent layers: Residual Net
    ([He, et al. 2016](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf))
    containing “Residual Block” which supports some input of one layer to be passed
    to the component two layers later.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/42fc43168dbb19b56d2e2e397843442b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Fig. 3\. Illustration of the human visual cortex system. (Image source: [Wang
    & Raj 2017](https://arxiv.org/abs/1702.07800))'
  prefs: []
  type: TYPE_NORMAL
- en: Convolution is a mathematical term, here referring to an operation between two
    matrices. The convolutional layer has a fixed small matrix defined, also called
    kernel or filter. As the kernel is sliding, or convolving, across the matrix representation
    of the input image, it is computing the element-wise multiplication of the values
    in the kernel matrix and the original image values. [Specially designed kernels](http://setosa.io/ev/image-kernels/)
    can process images for common purposes like blurring, sharpening, edge detection
    and many others, fast and efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/5362f324530b74b21d5b6e6d92a108eb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Fig. 4\. The LeNet architecture consists of two sets of convolutional, activation,
    and pooling layers, followed by a fully-connected layer, activation, another fully-connected
    layer, and finally a softmax classifier (Image source: [http://deeplearning.net/tutorial/lenet.html](http://deeplearning.net/tutorial/lenet.html))'
  prefs: []
  type: TYPE_NORMAL
- en: '[Convolutional](http://ufldl.stanford.edu/tutorial/supervised/FeatureExtractionUsingConvolution/)
    and [pooling](http://ufldl.stanford.edu/tutorial/supervised/Pooling/) (or “sub-sampling”
    in Fig. 4) layers act like the V1, V2 and V4 visual cortex units, responding to
    feature extraction. The object recognition reasoning happens in the later fully-connected
    layers which consume the extracted features.'
  prefs: []
  type: TYPE_NORMAL
- en: Recurrent Neural Network
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A sequence model is usually designed to transform an input sequence into an
    output sequence that lives in a different domain. Recurrent neural network, short
    for “RNN”, is suitable for this purpose and has shown tremendous improvement in
    problems like handwriting recognition, speech recognition, and machine translation
    ([Sutskever et al. 2011](http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Sutskever_524.pdf),
    [Liwicki et al. 2007](http://www6.in.tum.de/Main/Publications/Liwicki2007a.pdf)).
  prefs: []
  type: TYPE_NORMAL
- en: A recurrent neural network model is born with the capability to process long
    sequential data and to tackle tasks with context spreading in time. The model
    processes one element in the sequence at one time step. After computation, the
    newly updated unit state is passed down to the next time step to facilitate the
    computation of the next element. Imagine the case when an RNN model reads all
    the Wikipedia articles, character by character, and then it can predict the following
    words given the context.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/afe7794966b70dc9894dbd0c766fd68f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Fig. 5\. A recurrent neural network with one hidden unit (left) and its unrolling
    version in time (right). The unrolling version illustrates what happens in time:
    $s\_{t-1}$, $s\_{t}$, and $s\_{t+1}$ are the same unit with different states at
    different time steps $t-1$, $t$, and $t+1$. (Image source: [LeCun, Bengio, and
    Hinton, 2015](http://pages.cs.wisc.edu/~dyer/cs540/handouts/deep-learning-nature2015.pdf);
    [Fig. 5](https://www.nature.com/nature/journal/v521/n7553/fig_tab/nature14539_F5.html))'
  prefs: []
  type: TYPE_NORMAL
- en: However, simple perceptron neurons that linearly combine the current input element
    and the last unit state may easily lose the long-term dependencies. For example,
    we start a sentence with “Alice is working at …” and later after a whole paragraph,
    we want to start the next sentence with “She” or “He” correctly. If the model
    forgets the character’s name “Alice”, we can never know. To resolve the issue,
    researchers created a special neuron with a much more complicated internal structure
    for memorizing long-term context, named [“Long-short term memory (LSTM)”](http://web.eecs.utk.edu/~itamar/courses/ECE-692/Bobby_paper1.pdf)
    cell. It is smart enough to learn for how long it should memorize the old information,
    when to forget, when to make use of the new data, and how to combine the old memory
    with new input. This [introduction](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
    is so well written that I recommend everyone with interest in LSTM to read it.
    It has been officially promoted in the [Tensorflow documentation](https://www.tensorflow.org/tutorials/recurrent)
    ;-)
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2269803731918b77c850bf1ba23a5120.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Fig. 6\. The structure of a LSTM cell. (Image source: [http://colah.github.io/posts/2015-08-Understanding-LSTMs](http://colah.github.io/posts/2015-08-Understanding-LSTMs))'
  prefs: []
  type: TYPE_NORMAL
- en: To demonstrate the power of RNNs, [Andrej Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)
    built a character-based language model using RNN with LSTM cells. Without knowing
    any English vocabulary beforehand, the model could learn the relationship between
    characters to form words and then the relationship between words to form sentences.
    It could achieve a decent performance even without a huge set of training data.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/387ae59519145a9aaf72ef5c9fda65f1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Fig. 7\. A character-based recurrent neural network model writes like a Shakespeare.
    (Image source: [http://karpathy.github.io/2015/05/21/rnn-effectiveness](http://karpathy.github.io/2015/05/21/rnn-effectiveness))'
  prefs: []
  type: TYPE_NORMAL
- en: 'RNN: Sequence-to-Sequence Model'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The [sequence-to-sequence model](https://arxiv.org/pdf/1406.1078.pdf) is an
    extended version of RNN, but its application field is distinguishable enough that
    I would like to list it in a separated section. Same as RNN, a sequence-to-sequence
    model operates on sequential data, but particularly it is commonly used to develop
    chatbots or personal assistants, both generating meaningful response for input
    questions. A sequence-to-sequence model consists of two RNNs, encoder and decoder.
    The encoder learns the contextual information from the input words and then hands
    over the knowledge to the decoder side through a “**context vector**” (or “thought
    vector”, as shown in Fig 8.). Finally, the decoder consumes the context vector
    and generates proper responses.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/ee729f893fec4aae3971521fd9c1e2dc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Fig. 8\. A sequence-to-sequence model for generating Gmail auto replies. (Image
    source: [https://research.googleblog.com/2015/11/computer-respond-to-this-email.html](https://research.googleblog.com/2015/11/computer-respond-to-this-email.html))'
  prefs: []
  type: TYPE_NORMAL
- en: Autoencoders
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Different from the previous models, autoencoders are for unsupervised learning.
    It is designed to learn a **low-dimensional** representation of a **high-dimensional**
    data set, similar to what [Principal Components Analysis (PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis)
    does. The autoencoder model tries to learn an approximation function $ f(x) \approx
    x $ to reproduce the input data. However, it is restricted by a bottleneck layer
    in the middle with a very small number of nodes. With limited capacity, the model
    is forced to form a very efficient encoding of the data, that is essentially the
    low-dimensional code we learned.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/61cdc6cabf29ed29c44756da2fded700.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Fig. 9\. An autoencoder model has a bottleneck layer with only a few neurons.
    (Image source: Geoffrey Hinton’s Coursera class ["Neural Networks for Machine
    Learning"](https://www.coursera.org/learn/neural-networks) - [Week 15](https://www.coursera.org/learn/neural-networks/home/week/15))'
  prefs: []
  type: TYPE_NORMAL
- en: '[Hinton and Salakhutdinov](https://pdfs.semanticscholar.org/7d76/b71b700846901ac4ac119403aa737a285e36.pdf)
    used autoencoders to compress documents on a variety of topics. As shown in Fig
    10, when both PCA and autoencoder were applied to reduce the documents onto two
    dimensions, autoencoder demonstrated a much better outcome. With the help of autoencoder,
    we can do efficient data compression to speed up the information retrieval including
    both documents and images.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4fd189f148662ce4f6599c9909331d05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Fig. 10\. The outputs of PCA (left) and autoencoder (right) when both try to
    compress documents into two numbers. (Image source: [Hinton & Salakhutdinov 2006](https://www.cs.toronto.edu/~hinton/science.pdf))'
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement (Deep) Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since I started my post with AlphaGo, let us dig a bit more on why AlphaGo worked
    out. [Reinforcement learning (“RL”)](https://en.wikipedia.org/wiki/Reinforcement_learning)
    is one of the secrets behind its success. RL is a subfield of machine learning
    which allows machines and software agents to automatically determine the optimal
    behavior within a given context, with a goal to maximize the long-term performance
    measured by a given metric.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/44e6d4729f71b8419f8672d2ed524c65.png) ![](../Images/25c814659e7592d12edb2584417f68f1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Fig. 11\. AlphaGo neural network training pipeline and architecture. (Image
    source: [Silver et al. 2016](https://www.nature.com/articles/nature16961))'
  prefs: []
  type: TYPE_NORMAL
- en: The AlphaGo system starts with a supervised learning process to train a fast
    rollout policy and a policy network, relying on the manually curated training
    dataset of professional players’ games. It learns what is the best strategy given
    the current position on the game board. Then it applies reinforcement learning
    by setting up self-play games. The RL policy network gets improved when it wins
    more and more games against previous versions of the policy network. In the self-play
    stage, AlphaGo becomes stronger and stronger by playing against itself without
    requiring additional external training data.
  prefs: []
  type: TYPE_NORMAL
- en: Generative Adversarial Network
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Generative adversarial network](https://arxiv.org/pdf/1406.2661.pdf), short
    for “GAN”, is a type of deep generative models. GAN is able to create new examples
    after learning through the real data. It is consist of two models competing against
    each other in a zero-sum game framework. The famous deep learning researcher [Yann
    LeCun](http://yann.lecun.com/) gave it a super high praise: Generative Adversarial
    Network is the most interesting idea in the last ten years in machine learning.
    (See the Quora question: [“What are some recent and potentially upcoming breakthroughs
    in deep learning?”](https://www.quora.com/What-are-some-recent-and-potentially-upcoming-breakthroughs-in-deep-learning))'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/75788e705ec2c612c9034c3f8bf8af0d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Fig. 12\. The architecture of a generative adversarial network. (Image source:
    [http://www.kdnuggets.com/2017/01/generative-adversarial-networks-hot-topic-machine-learning.html](http://www.kdnuggets.com/2017/01/generative-adversarial-networks-hot-topic-machine-learning.html))'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the [original GAN paper](https://arxiv.org/pdf/1406.2661.pdf), GAN was proposed
    to generate meaningful images after learning from real photos. It comprises two
    independent models: the **Generator** and the **Discriminator**. The generator
    produces fake images and sends the output to the discriminator model. The discriminator
    works like a judge, as it is optimized for identifying the real photos from the
    fake ones. The generator model is trying hard to cheat the discriminator while
    the judge is trying hard not to be cheated. This interesting zero-sum game between
    these two models motivates both to develop their designed skills and improve their
    functionalities. Eventually, we take the generator model for producing new images.'
  prefs: []
  type: TYPE_NORMAL
- en: Toolkits and Libraries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After learning all these models, you may start wondering how you can implement
    the models and use them for real. Fortunately, we have many open source toolkits
    and libraries for building deep learning models. [Tensorflow](https://www.tensorflow.org/)
    is fairly new but has attracted a lot of popularity. It turns out, TensorFlow
    was [the most forked Github project of 2015](http://deliprao.com/archives/168).
    All that happened in a period of 2 months after its release in Nov 2015.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1709f70e5aa87c0abed2dc44b0993d07.png)'
  prefs: []
  type: TYPE_IMG
- en: How to Learn?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If you are very new to the field and willing to devote some time to studying
    deep learning in a more systematic way, I would recommend you to start with the
    book [Deep Learning](https://www.amazon.com/Deep-Learning-Adaptive-Computation-Machine/dp/0262035618/ref=sr_1_1?s=books&ie=UTF8&qid=1499413305&sr=1-1&keywords=deep+learning)
    by Ian Goodfellow, Yoshua Bengio, and Aaron Courville. The Coursera course [“Neural
    Networks for Machine Learning”](https://www.coursera.org/learn/neural-networks)
    by Geoffrey Hinton ([Godfather of deep learning!](https://youtu.be/uAu3jQWaN6E)).
    The content for the course was prepared around 2006, pretty old, but it helps
    you build up a solid foundation for understanding deep learning models and expedite
    further exploration.
  prefs: []
  type: TYPE_NORMAL
- en: Meanwhile, maintain your curiosity and passion. The field is making progress
    every day. Even classical or widely adopted deep learning models may just have
    been proposed 1-2 years ago. Reading academic papers can help you learn stuff
    in depth and keep up with the cutting-edge findings.
  prefs: []
  type: TYPE_NORMAL
- en: Useful resources
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Google Scholar: [http://scholar.google.com](http://scholar.google.com)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'arXiv cs section: [https://arxiv.org/list/cs/recent](https://arxiv.org/list/cs/recent)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Unsupervised Feature Learning and Deep Learning Tutorial](http://ufldl.stanford.edu/tutorial/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Tensorflow Tutorials](https://www.tensorflow.org/tutorials/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data Science Weekly
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets](http://www.kdnuggets.com/2017/01/generative-adversarial-networks-hot-topic-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tons of blog posts and online tutorials
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Related [Cousera](http://coursera.com) courses
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[awesome-deep-learning-papers](https://github.com/terryum/awesome-deep-learning-papers)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Blog posts mentioned
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Explained Visually: Image Kernels](http://setosa.io/ev/image-kernels)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Computer, respond to this email.](https://research.googleblog.com/2015/11/computer-respond-to-this-email.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interesting blogs worthy of checking
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[www.wildml.com](http://www.wildml.com)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[colah.github.io](http://colah.github.io/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[karpathy.github.io](http://karpathy.github.io/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[blog.openai.com](https://blog.openai.com)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Papers mentioned
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[1] He, Kaiming, et al. [“Deep residual learning for image recognition.”](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)
    Proc. IEEE Conf. on computer vision and pattern recognition. 2016.'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] Wang, Haohan, Bhiksha Raj, and Eric P. Xing. [“On the Origin of Deep Learning.”](https://arxiv.org/pdf/1702.07800.pdf)
    arXiv preprint arXiv:1702.07800, 2017.'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] Sutskever, Ilya, James Martens, and Geoffrey E. Hinton. [“Generating text
    with recurrent neural networks.”](http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Sutskever_524.pdf)
    Proc. of the 28th Intl. Conf. on Machine Learning (ICML). 2011.'
  prefs: []
  type: TYPE_NORMAL
- en: '[4] Liwicki, Marcus, et al. [“A novel approach to on-line handwriting recognition
    based on bidirectional long short-term memory networks.”](http://www6.in.tum.de/Main/Publications/Liwicki2007a.pdf)
    Proc. of 9th Intl. Conf. on Document Analysis and Recognition. 2007.'
  prefs: []
  type: TYPE_NORMAL
- en: '[5] LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. [“Deep learning.”](http://pages.cs.wisc.edu/~dyer/cs540/handouts/deep-learning-nature2015.pdf)
    Nature 521.7553 (2015): 436-444.'
  prefs: []
  type: TYPE_NORMAL
- en: '[6] Hochreiter, Sepp, and Jurgen Schmidhuber. [“Long short-term memory.”](http://web.eecs.utk.edu/~itamar/courses/ECE-692/Bobby_paper1.pdf)
    Neural computation 9.8 (1997): 1735-1780.'
  prefs: []
  type: TYPE_NORMAL
- en: '[7] Cho, Kyunghyun. et al. [“Learning phrase representations using RNN encoder-decoder
    for statistical machine translation.”](https://arxiv.org/pdf/1406.1078.pdf) Proc.
    Conference on Empirical Methods in Natural Language Processing 1724–1734 (2014).'
  prefs: []
  type: TYPE_NORMAL
- en: '[8] Hinton, Geoffrey E., and Ruslan R. Salakhutdinov. [“Reducing the dimensionality
    of data with neural networks.”](https://pdfs.semanticscholar.org/7d76/b71b700846901ac4ac119403aa737a285e36.pdf)
    science 313.5786 (2006): 504-507.'
  prefs: []
  type: TYPE_NORMAL
- en: '[9] Silver, David, et al. [“Mastering the game of Go with deep neural networks
    and tree search.”](http://web.iitd.ac.in/~sumeet/Silver16.pdf) Nature 529.7587
    (2016): 484-489.'
  prefs: []
  type: TYPE_NORMAL
- en: '[10] Goodfellow, Ian, et al. [“Generative adversarial nets.”](https://arxiv.org/pdf/1406.2661.pdf)
    NIPS, 2014.'
  prefs: []
  type: TYPE_NORMAL
