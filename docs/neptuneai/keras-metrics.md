# Keras Metrics:æ‚¨éœ€è¦çŸ¥é“çš„ä¸€åˆ‡

> åŽŸæ–‡ï¼š<https://web.archive.org/web/https://neptune.ai/blog/keras-metrics>

Keras æŒ‡æ ‡æ˜¯ç”¨äºŽè¯„ä¼°æ·±åº¦å­¦ä¹ æ¨¡åž‹æ€§èƒ½çš„å‡½æ•°ã€‚ä¸ºæ‚¨çš„é—®é¢˜é€‰æ‹©ä¸€ä¸ªå¥½çš„åº¦é‡æ ‡å‡†é€šå¸¸æ˜¯ä¸€é¡¹å›°éš¾çš„ä»»åŠ¡ã€‚

*   ä½ éœ€è¦äº†è§£ã€tf.keras å’Œ tf.keras ä¸­å“ªäº›æŒ‡æ ‡å·²ç»å¯ç”¨ä»¥åŠå¦‚ä½•ä½¿ç”¨å®ƒä»¬ï¼Œ
*   åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œæ‚¨éœ€è¦**å®šä¹‰æ‚¨è‡ªå·±çš„å®šåˆ¶æŒ‡æ ‡**ï¼Œå› ä¸ºæ‚¨æ­£åœ¨å¯»æ‰¾çš„æŒ‡æ ‡æ²¡æœ‰éš Keras ä¸€èµ·æä¾›ã€‚
*   æœ‰æ—¶ï¼Œæ‚¨å¸Œæœ›**é€šè¿‡åœ¨æ¯ä¸ªæ—¶æœŸåŽæŸ¥çœ‹ ROC æ›²çº¿æˆ–æ··æ·†çŸ©é˜µ**ç­‰å›¾è¡¨æ¥ç›‘æŽ§æ¨¡åž‹æ€§èƒ½ã€‚

### æœ¬æ–‡å°†è§£é‡Šä¸€äº›æœ¯è¯­:

*   keras åº¦é‡å‡†ç¡®æ€§
*   keras ç¼–è¯‘æŒ‡æ ‡
*   keras è‡ªå®šä¹‰æŒ‡æ ‡
*   å›žå½’çš„ keras åº¦é‡
*   keras æ··æ·†çŸ©é˜µ
*   tf.kerac.metrics.meaniou
*   tf.keras.metrics f1 åˆ†æ•°
*   tf.keras.metrics.auc

## Keras metrics 101

åœ¨ Keras ä¸­ï¼Œåº¦é‡åœ¨ç¼–è¯‘é˜¶æ®µä¼ é€’ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚æ‚¨å¯ä»¥é€šè¿‡é€—å·åˆ†éš”æ¥ä¼ é€’å¤šä¸ªæŒ‡æ ‡ã€‚

```py
from keras import metrics

model.compile(loss='mean_squared_error', optimizer='sgd',
              metrics=[metrics.mae,
                       metrics.categorical_accuracy])
```

æ‚¨åº”è¯¥å¦‚ä½•é€‰æ‹©è¿™äº›è¯„ä¼°æŒ‡æ ‡ï¼Ÿ

å…¶ä¸­ä¸€äº›åœ¨ Keras ä¸­å¯ç”¨ï¼Œå¦ä¸€äº›åœ¨ tf.keras ä¸­å¯ç”¨ã€‚

è®©æˆ‘ä»¬å›žé¡¾ä¸€ä¸‹æ‰€æœ‰è¿™äº›æƒ…å†µã€‚

## Keras ä¸­æä¾›äº†å“ªäº›æŒ‡æ ‡ï¼Ÿ

Keras æä¾›äº†ä¸°å¯Œçš„å†…ç½®æŒ‡æ ‡ã€‚æ ¹æ®ä½ çš„é—®é¢˜ï¼Œä½ ä¼šä½¿ç”¨ä¸åŒçš„ã€‚

è®©æˆ‘ä»¬æ¥çœ‹çœ‹ä½ å¯èƒ½æ­£åœ¨è§£å†³çš„ä¸€äº›é—®é¢˜ã€‚

### äºŒå…ƒåˆ†ç±»

äºŒå…ƒåˆ†ç±»åº¦é‡ç”¨äºŽåªæ¶‰åŠä¸¤ä¸ªç±»åˆ«çš„è®¡ç®—ã€‚ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­æ˜¯å»ºç«‹æ·±åº¦å­¦ä¹ **æ¨¡åž‹æ¥é¢„æµ‹çŒ«å’Œç‹—**ã€‚æˆ‘ä»¬æœ‰ä¸¤ä¸ªç±»åˆ«è¦é¢„æµ‹ï¼Œé˜ˆå€¼å†³å®šäº†å®ƒä»¬ä¹‹é—´çš„åˆ†ç¦»ç‚¹ã€‚ ***binary_accuracy*** å’Œ ***accuracy*** å°±æ˜¯ Keras ä¸­çš„ä¸¤ä¸ªè¿™æ ·çš„å‡½æ•°ã€‚

***binary_accuracy** ï¼Œ*ä¾‹å¦‚ï¼Œè®¡ç®—äºŒè¿›åˆ¶åˆ†ç±»é—®é¢˜çš„æ‰€æœ‰é¢„æµ‹çš„å¹³å‡å‡†ç¡®çŽ‡ã€‚

```py
keras.metrics.binary_accuracy(y_true, y_pred, threshold=0.5)

```

***å‡†ç¡®æ€§*** æŒ‡æ ‡è®¡ç®—æ‰€æœ‰é¢„æµ‹çš„å‡†ç¡®çŽ‡ã€‚ *y_true* ä»£è¡¨çœŸå®žæ ‡ç­¾ï¼Œè€Œ *y_pred* ä»£è¡¨é¢„æµ‹æ ‡ç­¾ã€‚

```py
keras.metrics.accuracy(y_true, y_pred)

```

***confusion_matrix*** æ˜¾ç¤ºä¸€ä¸ªè¡¨æ ¼ï¼Œæ˜¾ç¤ºçœŸé˜³æ€§ã€çœŸé˜´æ€§ã€å‡é˜³æ€§å’Œå‡é˜´æ€§ã€‚

```py
keras.metrics.confusion_matrix(y_test, y_pred)

```

åœ¨ä¸Šé¢çš„æ··æ·†çŸ©é˜µä¸­ï¼Œæ¨¡åž‹åšå‡ºäº† 3305 + 375 ä¸ªæ­£ç¡®çš„é¢„æµ‹ï¼Œ106 + 714 ä¸ªé”™è¯¯çš„é¢„æµ‹ã€‚

ä½ ä¹Ÿå¯ä»¥æŠŠå®ƒæƒ³è±¡æˆä¸€ä¸ª matplotlib å›¾è¡¨ï¼Œæˆ‘ä»¬ç¨åŽä¼šè®²åˆ°ã€‚

### ä»€ä¹ˆæ˜¯ Keras ç²¾åº¦ï¼Ÿ

è¿™ä¼¼ä¹Žå¾ˆç®€å•ï¼Œä½†å®žé™…ä¸Šå¹¶ä¸æ˜Žæ˜¾ã€‚

> æœ¯è¯­â€œå‡†ç¡®åº¦â€æ˜¯ä¸€ä¸ªè¡¨è¾¾å¼ï¼Œè®©[è®­ç»ƒæ–‡ä»¶](https://web.archive.org/web/20220926093651/https://github.com/keras-team/keras/blob/d8b226f26b35348d934edb1213061993e7e5a1fa/keras/engine/training.py#L651)å†³å®šåº”è¯¥ä½¿ç”¨å“ªä¸ªåº¦é‡æ ‡å‡†(**äºŒè¿›åˆ¶å‡†ç¡®åº¦**ã€**åˆ†ç±»å‡†ç¡®åº¦**æˆ–**ç¨€ç–åˆ†ç±»å‡†ç¡®åº¦**)ã€‚è¯¥å†³å®šåŸºäºŽæŸäº›å‚æ•°ï¼Œå¦‚è¾“å‡ºå½¢çŠ¶(ç”±è¯¥å±‚äº§ç”Ÿçš„å¼ é‡çš„å½¢çŠ¶ï¼Œå¹¶ä¸”å°†æ˜¯ä¸‹ä¸€å±‚çš„è¾“å…¥)å’ŒæŸå¤±å‡½æ•°ã€‚

å› æ­¤ï¼Œæœ‰æ—¶è´¨ç–‘ç”šè‡³æ˜¯æœ€ç®€å•çš„äº‹æƒ…ä¹Ÿæ˜¯å¥½çš„ï¼Œå°¤å…¶æ˜¯å½“æ‚¨çš„åº¦é‡å‘ç”Ÿäº†æ„æƒ³ä¸åˆ°çš„äº‹æƒ…æ—¶ã€‚

### å¤šç±»åˆ†ç±»

è¿™äº›åº¦é‡ç”¨äºŽæ¶‰åŠä¸¤ä¸ªä»¥ä¸Šç±»åˆ«çš„åˆ†ç±»**é—®é¢˜ã€‚æ‰©å±•æˆ‘ä»¬çš„åŠ¨ç‰©åˆ†ç±»ä¾‹å­ï¼Œä½ å¯ä»¥æœ‰ä¸‰ç§åŠ¨ç‰©ï¼ŒçŒ«ã€ç‹—å’Œç†Šã€‚å› ä¸ºæˆ‘ä»¬è¦å¯¹ä¸¤ç§ä»¥ä¸Šçš„åŠ¨ç‰©è¿›è¡Œåˆ†ç±»ï¼Œæ‰€ä»¥è¿™æ˜¯ä¸€ä¸ªå¤šç±»åˆ†ç±»é—®é¢˜ã€‚**

*y_true* çš„å½¢çŠ¶æ˜¯æ¡ç›®æ•°ä¹˜ä»¥ 1ï¼Œå³(nï¼Œ1 ),ä½†æ˜¯ *y_pred* çš„å½¢çŠ¶æ˜¯æ¡ç›®æ•°ä¹˜ä»¥ç±»æ•°(nï¼Œc)

***category _ accuracy***æŒ‡æ ‡è®¡ç®—æ‰€æœ‰é¢„æµ‹çš„å¹³å‡å‡†ç¡®çŽ‡ã€‚

```py
keras.metrics.categorical_accuracy(y_true, y_pred)

```

***sparse _ categorial _ accuracy***ä¸Ž*categorial _ accuracy*ç±»ä¼¼ï¼Œä½†å¤§å¤šåœ¨å¯¹ç¨€ç–ç›®æ ‡è¿›è¡Œé¢„æµ‹æ—¶ä½¿ç”¨**ã€‚ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­æ˜¯åœ¨æ·±åº¦å­¦ä¹ é—®é¢˜ä¸­å¤„ç†æ–‡æœ¬ï¼Œå¦‚ word2vecã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä¸€ä¸ªäººç”¨**æ•°åƒä¸ªç±»**å·¥ä½œï¼Œç›®çš„æ˜¯é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ã€‚è¿™ä¸ªä»»åŠ¡ä¼šäº§ç”Ÿä¸€ç§æƒ…å†µï¼Œy_true æ˜¯ä¸€ä¸ªå‡ ä¹Žå…¨æ˜¯é›¶çš„å·¨å¤§çŸ©é˜µï¼Œè¿™æ˜¯ä½¿ç”¨ç¨€ç–çŸ©é˜µçš„æœ€ä½³ä½ç½®ã€‚**

```py
keras.metrics.sparse_categorical_accuracy(y_true, y_pred)

```

***top _ k _ category _ accuracy***è®¡ç®— top-k åˆ†ç±»å‡†ç¡®çŽ‡ã€‚æˆ‘ä»¬ä»Žæˆ‘ä»¬çš„æ¨¡åž‹ä¸­å–å‡ºå‰ k ä¸ªé¢„æµ‹ç±»ï¼Œå¹¶æŸ¥çœ‹æ­£ç¡®çš„ç±»æ˜¯å¦è¢«é€‰ä¸ºå‰ k ä¸ªã€‚å¦‚æžœæ˜¯ï¼Œæˆ‘ä»¬è¯´æˆ‘ä»¬çš„æ¨¡åž‹æ˜¯æ­£ç¡®çš„ã€‚

```py
keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=5)

```

### å›žå½’

å›žå½’é—®é¢˜ä¸­ä½¿ç”¨çš„åº¦é‡åŒ…æ‹¬**å‡æ–¹è¯¯å·®ã€å¹³å‡ç»å¯¹è¯¯å·®å’Œå¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®ã€‚**è¿™äº›æŒ‡æ ‡ç”¨äºŽé¢„æµ‹æˆ¿å±‹é”€å”®å’Œä»·æ ¼ç­‰æ•°å€¼ã€‚æŸ¥çœ‹è¿™ä¸ªå‚è€ƒèµ„æ–™ï¼ŒèŽ·å¾—å…³äºŽå›žå½’åº¦é‡çš„[å®Œæ•´æŒ‡å—ã€‚](https://web.archive.org/web/20220926093651/https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics)

```py
from keras import metrics

model.compile(loss='mse', optimizer='adam', 
              metrics=[metrics.mean_squared_error, 
                       metrics.mean_absolute_error, 
                       metrics.mean_absolute_percentage_error])
                       metrics.categorical_accuracy])
```

## å¦‚ä½•åœ¨ Keras ä¸­åˆ›å»ºè‡ªå®šä¹‰æŒ‡æ ‡ï¼Ÿ

æ­£å¦‚æˆ‘ä»¬å‰é¢æåˆ°çš„ï¼ŒKeras è¿˜å…è®¸æ‚¨å®šä¹‰è‡ªå·±çš„å®šåˆ¶æŒ‡æ ‡ã€‚

æ‚¨å®šä¹‰çš„å‡½æ•°**å¿…é¡»å°† *y_true* å’Œ *y_pred* ä½œä¸ºå‚æ•°ï¼Œå¹¶ä¸”å¿…é¡»è¿”å›žå•ä¸ªå¼ é‡å€¼**ã€‚è¿™äº›å¯¹è±¡æ˜¯å…·æœ‰ float32 æ•°æ®ç±»åž‹çš„å¼ é‡ç±»åž‹ã€‚å¯¹è±¡çš„å½¢çŠ¶æ˜¯è¡Œæ•°ä¹˜ä»¥ 1ã€‚ä¾‹å¦‚ï¼Œå¦‚æžœæœ‰ 4ï¼Œ500 ä¸ªæ¡ç›®ï¼Œå½¢çŠ¶å°†æ˜¯(4500ï¼Œ1)ã€‚

å¯ä»¥åœ¨æ·±åº¦å­¦ä¹ æ¨¡åž‹çš„ç¼–è¯‘é˜¶æ®µä¼ é€’å‡½æ•°æ¥ä½¿ç”¨ã€‚

```py
model.compile(...metrics=[your_custom_metric])
```

### å¦‚ä½•è®¡ç®— Keras ä¸­çš„ F1 åˆ†æ•°(ç²¾åº¦ï¼Œå¬å›žä½œä¸ºåŠ åˆ†)ï¼Ÿ

è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•åœ¨ Keras ä¸­è®¡ç®— **f1 åˆ†æ•°ã€ç²¾ç¡®åº¦å’Œå¬å›žçŽ‡ã€‚**æˆ‘ä»¬å°†ä¸ºå¤šç±»åœºæ™¯åˆ›å»ºå®ƒï¼Œä½†æ‚¨ä¹Ÿå¯ä»¥å°†å…¶ç”¨äºŽäºŒè¿›åˆ¶åˆ†ç±»ã€‚

f1 åˆ†æ•°æ˜¯ç²¾ç¡®åº¦å’Œå¬å›žçŽ‡çš„åŠ æƒå¹³å‡å€¼ã€‚å› æ­¤ï¼Œä¸ºäº†è®¡ç®— f1ï¼Œæˆ‘ä»¬éœ€è¦é¦–å…ˆåˆ›å»ºè®¡ç®—ç²¾åº¦å’Œå¬å›žçŽ‡çš„å‡½æ•°ã€‚è¯·æ³¨æ„ï¼Œåœ¨å¤šç±»åœºæ™¯ä¸­ï¼Œæ‚¨éœ€è¦æŸ¥çœ‹æ‰€æœ‰çš„ç±»ï¼Œè€Œä¸ä»…ä»…æ˜¯æ­£ç±»(è¿™æ˜¯äºŒè¿›åˆ¶åˆ†ç±»çš„æƒ…å†µ)

```py
def recall(y_true, y_pred):
    y_true = K.ones_like(y_true) 
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    all_positives = K.sum(K.round(K.clip(y_true, 0, 1)))

    recall = true_positives / (all_positives + K.epsilon())
    return recall

def precision(y_true, y_pred):
    y_true = K.ones_like(y_true) 
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))

    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    return precision

def f1_score(y_true, y_pred):
    precision = precision_m(y_true, y_pred)
    recall = recall_m(y_true, y_pred)
    return 2*((precision*recall)/(precision+recall+K.epsilon()))

```

ä¸‹ä¸€æ­¥æ˜¯åœ¨æˆ‘ä»¬æ·±åº¦å­¦ä¹ æ¨¡åž‹çš„ç¼–è¯‘é˜¶æ®µä½¿ç”¨è¿™äº›å‡½æ•°ã€‚æˆ‘ä»¬è¿˜æ·»åŠ äº†é»˜è®¤å¯ç”¨çš„ Keras *å‡†ç¡®æ€§*æŒ‡æ ‡ã€‚

```py
model.compile(...,metrics=['accuracy', f1_score, precision, recall])

```

çŽ°åœ¨è®©æˆ‘ä»¬æ ¹æ®è®­ç»ƒé›†å’Œæµ‹è¯•é›†æ¥è°ƒæ•´æ¨¡åž‹ã€‚

```py
model.fit(x_train, y_train, epochs=5)

```

çŽ°åœ¨æ‚¨å¯ä»¥è¯„ä¼°æ‚¨çš„æ¨¡åž‹ï¼Œå¹¶è®¿é—®æ‚¨åˆšåˆšåˆ›å»ºçš„æŒ‡æ ‡ã€‚

```py
(loss, 
accuracy, 
f1_score, precision, recall) = model.evaluate(x_test, y_test, verbose=1)

```

å¾ˆå¥½ï¼Œæ‚¨çŽ°åœ¨çŸ¥é“å¦‚ä½•åœ¨ keras ä¸­åˆ›å»ºå®šåˆ¶æŒ‡æ ‡äº†ã€‚

ä¹Ÿå°±æ˜¯è¯´ï¼Œæœ‰æ—¶ä½ å¯ä»¥ä½¿ç”¨å·²ç»å­˜åœ¨çš„ä¸œè¥¿ï¼Œåªæ˜¯åœ¨ä¸€ä¸ªä¸åŒçš„åº“ä¸­ï¼Œæ¯”å¦‚ tf.kerasðŸ™‚

## tf.keras ä¸­æœ‰å“ªäº›æŒ‡æ ‡ï¼Ÿ

æœ€è¿‘ **Keras å·²ç»æˆä¸º TensorFlow** ä¸­çš„æ ‡å‡† APIï¼Œæœ‰è®¸å¤šæœ‰ç”¨çš„æŒ‡æ ‡å¯ä¾›æ‚¨ä½¿ç”¨ã€‚

è®©æˆ‘ä»¬æ¥çœ‹çœ‹å…¶ä¸­çš„ä¸€äº›ã€‚ä¸Žåœ¨ Keras ä¸­åªä½¿ç”¨ *keras.metrics* å‡½æ•°è°ƒç”¨æŒ‡æ ‡ä¸åŒï¼Œåœ¨ tf.keras ä¸­ï¼Œæ‚¨å¿…é¡»å®žä¾‹åŒ–ä¸€ä¸ª*æŒ‡æ ‡*ç±»ã€‚

ä¾‹å¦‚:

```py
tf.keras.metrics.Accuracy() 

```

keras æŒ‡æ ‡å’Œ tf.keras ä¹‹é—´æœ‰å¾ˆå¤šé‡å ã€‚ä½†æ˜¯ï¼Œæœ‰ä¸€äº›æŒ‡æ ‡ä½ åªèƒ½åœ¨ tf.keras ä¸­æ‰¾åˆ°ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹é‚£äº›ã€‚

### tf.keras åˆ†ç±»æŒ‡æ ‡

***TF . keras . metrics . AUC***é€šè¿‡[é»Žæ›¼å’Œ](https://web.archive.org/web/20220926093651/https://www.khanacademy.org/math/ap-calculus-ab/ab-integration-new/ab-6-2/a/left-and-right-riemann-sums)è®¡ç®— ROC æ›²çº¿çš„è¿‘ä¼¼ AUC(æ›²çº¿ä¸‹é¢ç§¯)ã€‚

```py
model.compile('sgd', loss='mse', metrics=[tf.keras.metrics.AUC()])

```

æ‚¨å¯ä»¥ä½¿ç”¨ precisionï¼Œå›žæƒ³ä¸€ä¸‹æˆ‘ä»¬ä»¥å‰åœ¨ tf.keras ä¸­å®žçŽ°çš„å¼€ç®±å³ç”¨ã€‚

```py
model.compile('sgd', loss='mse', 
               metrics=[tf.keras.metrics.Precision(), 
                        tf.keras.metrics.Recall()])

```

### tf.keras ç»†åˆ†æŒ‡æ ‡

***TF . keras . metrics . meaniou***â€“*Mean Intersection-Over-Union*æ˜¯ç”¨äºŽè¯„ä¼°è¯­ä¹‰å›¾åƒåˆ†å‰²æ¨¡åž‹çš„åº¦é‡ã€‚æˆ‘ä»¬é¦–å…ˆè®¡ç®—æ¯ä¸ªç±»çš„æ¬ æ¡:

æ‰€æœ‰ç­çº§çš„å¹³å‡å€¼ã€‚

```py
model.compile(... metrics=[tf.keras.metrics.MeanIoU(num_classes=2)])

```

### tf.keras å›žå½’åº¦é‡

å°±åƒ Keras ä¸€æ ·ï¼Œtf.keras ä¹Ÿæœ‰ç±»ä¼¼çš„å›žå½’åº¦é‡ã€‚æˆ‘ä»¬ä¸ä¼šè¿‡å¤šè®¨è®ºå®ƒä»¬ï¼Œä½†æœ‰ä¸€ä¸ªæœ‰è¶£çš„æŒ‡æ ‡å€¼å¾—å¼ºè°ƒï¼Œå«åš ***è¡¨ç¤ºç›¸å¯¹è¯¯å·®*** ã€‚

***è¡¨ç¤ºç›¸å¯¹è¯¯å·®*** å–ä¸€æ¬¡è§‚æµ‹çš„ç»å¯¹è¯¯å·®ï¼Œé™¤ä»¥å¸¸æ•°ã€‚è¿™ä¸ªå¸¸æ•°ï¼Œ**å½’ä¸€åŒ–å› å­**ï¼Œå¯ä»¥å¯¹æ‰€æœ‰è§‚æµ‹å€¼ç›¸åŒï¼Œä¹Ÿå¯ä»¥å¯¹æ¯ä¸ªæ ·æœ¬ä¸åŒã€‚

å› æ­¤ï¼Œå¹³å‡ç›¸å¯¹è¯¯å·®æ˜¯ç›¸å¯¹è¯¯å·®çš„å¹³å‡å€¼ã€‚

```py
tf.keras.metrics.MeanRelativeError(normalizer=[1, 3, 2, 3])
```

## å¦‚ä½•åœ¨ tf.keras ä¸­åˆ›å»ºè‡ªå®šä¹‰æŒ‡æ ‡ï¼Ÿ

åœ¨ *tf.keras* ä¸­ï¼Œæ‚¨å¯ä»¥é€šè¿‡æ‰©å±• *keras.metrics.Metric* ç±»æ¥åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰æŒ‡æ ‡ã€‚

ä¸ºæ­¤ï¼Œæ‚¨å¿…é¡»è¦†ç›– update_stateã€result å’Œ reset_state å‡½æ•°:

*   ***ã€update _ state()***å¯¹çŠ¶æ€å˜é‡è¿›è¡Œæ‰€æœ‰æ›´æ–°å¹¶è®¡ç®—åº¦é‡ï¼Œ
*   ***result()*** ä»ŽçŠ¶æ€å˜é‡ä¸­è¿”å›žåº¦é‡å€¼ï¼Œ
*   ***reset_state()*** å°†æ¯ä¸ªæ—¶æœŸå¼€å§‹æ—¶çš„åº¦é‡å€¼è®¾ç½®ä¸ºé¢„å®šä¹‰çš„å¸¸æ•°(é€šå¸¸ä¸º 0)

```py
class MulticlassTruePositives(tf.keras.metrics.Metric):
    def __init__(self, name='multiclass_true_positives', **kwargs):
        super(MulticlassTruePositives, self).__init__(name=name, **kwargs)
        self.true_positives = self.add_weight(name='tp', initializer='zeros')

    def update_state(self, y_true, y_pred, sample_weight=None):
        y_pred = tf.reshape(tf.argmax(y_pred, axis=1), shape=(-1, 1))
        values = tf.cast(y_true, 'int32') == tf.cast(y_pred, 'int32')
        values = tf.cast(values, 'float32')
        if sample_weight is not None:
            sample_weight = tf.cast(sample_weight, 'float32')
            values = tf.multiply(values, sample_weight)
        self.true_positives.assign_add(tf.reduce_sum(values))

    def result(self):
        return self.true_positives

    def reset_states(self):

        self.true_positives.assign(0.)
```

ç„¶åŽæˆ‘ä»¬ç®€å•åœ°åœ¨ç¼–è¯‘é˜¶æ®µä¼ é€’å®ƒ:

```py
model.compile(...,metrics=[MulticlassTruePositives()])

```

## æ€§èƒ½å›¾è¡¨:Keras ä¸­çš„ ROC æ›²çº¿å’Œæ··æ·†çŸ©é˜µ

**æœ‰æ—¶ï¼Œæ€§èƒ½ä¸èƒ½ç”¨ä¸€ä¸ªæ•°å­—**æ¥è¡¨ç¤ºï¼Œè€Œæ˜¯ç”¨æ€§èƒ½å›¾è¡¨æ¥è¡¨ç¤ºã€‚è¿™ç§å›¾è¡¨çš„ä¾‹å­æœ‰ ROC æ›²çº¿æˆ–æ··æ·†çŸ©é˜µã€‚åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œæ‚¨å¯èƒ½å¸Œæœ›å°†è¿™äº›å›¾è¡¨è®°å½•åœ¨æŸä¸ªåœ°æ–¹ï¼Œä»¥ä¾¿è¿›ä¸€æ­¥æ£€æŸ¥ã€‚

ä¸ºäº†åšåˆ°è¿™ä¸€ç‚¹ï¼Œä½ éœ€è¦åˆ›å»ºä¸€ä¸ªå›žè°ƒå‡½æ•°ï¼Œå®ƒå°†åœ¨æ¯ä¸ªæ—¶æœŸç»“æŸæ—¶è·Ÿè¸ªä½ çš„æ¨¡åž‹çš„æ€§èƒ½ã€‚ç„¶åŽï¼Œä½ å¯ä»¥åœ¨ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­æˆ–è€…åœ¨[å®žéªŒè·Ÿè¸ªå·¥å…·](https://web.archive.org/web/20220926093651/https://neptune.ai/blog/best-ml-experiment-tracking-tools)ä¸­æŸ¥çœ‹æ”¹è¿›ã€‚è®©æˆ‘ä»¬å¼€å§‹å§ã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªå›žè°ƒï¼Œåœ¨æ¯ä¸ªæ—¶æœŸç»“æŸæ—¶åˆ›å»º ROC æ›²çº¿å’Œæ··æ·†çŸ©é˜µã€‚

```py
import os

from keras.callbacks import Callback
import matplotlib.pyplot as plt
import numpy as np
from scikitplot.metrics import plot_confusion_matrix, plot_roc

class PerformanceVisualizationCallback(Callback):
    def __init__(self, model, validation_data, image_dir):
        super().__init__()
        self.model = model
        self.validation_data = validation_data

        os.makedirs(image_dir, exist_ok=True)
        self.image_dir = image_dir

    def on_epoch_end(self, epoch, logs={}):
        y_pred = np.asarray(self.model.predict(self.validation_data[0]))
        y_true = self.validation_data[1]             
        y_pred_class = np.argmax(y_pred, axis=1)

        fig, ax = plt.subplots(figsize=(16,12))
        plot_confusion_matrix(y_true, y_pred_class, ax=ax)
        fig.savefig(os.path.join(self.image_dir, f'confusion_matrix_epoch_{epoch}'))

        fig, ax = plt.subplots(figsize=(16,12))
        plot_roc(y_true, y_pred, ax=ax)
        fig.savefig(os.path.join(self.image_dir, f'roc_curve_epoch_{epoch}'))

```

çŽ°åœ¨æˆ‘ä»¬ç®€å•åœ°å°†å®ƒä¼ é€’ç»™ *model.fit()* callbacks å‚æ•°ã€‚

```py
performance_cbk = PerformanceVisualizationCallback(
                      model=model,
                      validation_data=validation_data,
                      image_dir='performance_vizualizations')

history = model.fit(x=x_train,
                    y=y_train,
                    epochs=5,
                    validation_data=validation_data,
                    callbacks=[performance_cbk])
```

å¦‚æžœä½ æ„¿æ„ï¼Œä½ å¯ä»¥æœ‰å¤šä¸ªå›žè°ƒã€‚

çŽ°åœ¨ï¼Œæ‚¨å°†èƒ½å¤Ÿåœ¨æ¨¡åž‹è®­ç»ƒæ—¶çœ‹åˆ°è¿™äº›å¯è§†åŒ–æ•ˆæžœ:

ä½ ä¹Ÿå¯ä»¥åƒ Neptune ä¸€æ ·æŠŠä¸€åˆ‡è®°å½•åˆ°å®žéªŒè·Ÿè¸ªå·¥å…·ä¸­ã€‚è¿™ç§æ–¹æ³•å°†è®©æ‚¨åœ¨ä¸€ä¸ªåœ°æ–¹æ‹¥æœ‰æ‰€æœ‰çš„æ¨¡åž‹å…ƒæ•°æ®ã€‚ä¸ºæ­¤ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ [Neptune + TensorFlow / Keras é›†æˆ](https://web.archive.org/web/20220926093651/https://docs.neptune.ai/integrations-and-supported-tools/model-training/tensorflow-keras):

```py
from neptune.new.integrations.tensorflow_keras import NeptuneCallback
import neptune.new as neptune
from scikitplot.metrics import plot_confusion_matrix
import matplotlib.pyplot as plt

run = neptune.init(
        project='YOUR_WORKSAPCE/YOUR_PROJECT_NAME',
        api_token='YOUR_API_TOKEN')

```

è¯·æ³¨æ„ï¼Œæ‚¨ä¸éœ€è¦ä¸ºå›¾åƒåˆ›å»ºæ–‡ä»¶å¤¹ï¼Œå› ä¸ºå›¾è¡¨å°†ç›´æŽ¥å‘é€åˆ°æ‚¨çš„å·¥å…·ã€‚å¦ä¸€æ–¹é¢ï¼Œä½ å¿…é¡»[åˆ›å»ºä¸€ä¸ªé¡¹ç›®](https://web.archive.org/web/20220926093651/https://docs.neptune.ai/api-reference/management#.create_project)æ¥å¼€å§‹è·Ÿè¸ªä½ çš„è·‘æ­¥ã€‚

ä¸€æ—¦ä½ åšåˆ°äº†è¿™ä¸€ç‚¹ï¼Œä¸€åˆ‡ç…§å¸¸ã€‚

```py
neptune_cbk = NeptuneCallback(run=run, base_namespace='metrics')

history = model.fit(x=x_train,
                    y=y_train,
                    epochs=5,
                    validation_data=validation_data,
                    callbacks=[neptune_cbk])

fig, ax = plt.subplots(figsize=(16, 12))
plot_confusion_matrix(y_train, y_train_pred, ax=ax)

run['confusion_matrix'].upload(neptune.types.File.as_image(fig))

```

æ‚¨å¯ä»¥åœ¨[åº”ç”¨](https://web.archive.org/web/20220926093651/https://app.neptune.ai/common/tf-keras-integration/e/TFK-18/charts)ä¸­æŽ¢ç´¢æŒ‡æ ‡å’Œæ€§èƒ½å›¾è¡¨ã€‚

## å¦‚ä½•ç»˜åˆ¶ Keras åŽ†å²å¯¹è±¡ï¼Ÿ

æ¯å½“è°ƒç”¨ *fit()* æ—¶ï¼Œå®ƒéƒ½è¿”å›žä¸€ä¸ª ***åŽ†å²*** å¯¹è±¡ï¼Œè¯¥å¯¹è±¡å¯ç”¨äºŽå¯è§†åŒ–è®­ç»ƒåŽ†å²ã€‚**å®ƒåŒ…å«ä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­åŒ…å«ä¸ºè®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†è®¡ç®—çš„æ¯ä¸ªåŽ†å…ƒçš„æŸå¤±å’Œåº¦é‡å€¼**ã€‚

ä¾‹å¦‚ï¼Œè®©æˆ‘ä»¬æå–â€œ*å‡†ç¡®æ€§*â€æŒ‡æ ‡ï¼Œå¹¶ä½¿ç”¨ matplotlib ç»˜åˆ¶å®ƒã€‚

```py
import matplotlib.pyplot as plt

history = model.fit(x_train, y_train, 
                    validation_split=0.25, 
                    epochs=50, batch_size=16, verbose=1)

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_â€˜accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()
```

## Keras æŒ‡æ ‡ç¤ºä¾‹

å¥½äº†ï¼Œä½ å·²ç»èµ°äº†å¾ˆé•¿ä¸€æ®µè·¯ï¼Œå­¦åˆ°äº†å¾ˆå¤šã€‚ä¸ºäº†å”¤èµ·ä½ çš„è®°å¿†ï¼Œè®©æˆ‘ä»¬æŠŠå®ƒä»¬æ”¾åœ¨ä¸€ä¸ªä¾‹å­ä¸­ã€‚

æˆ‘ä»¬å°†ä»Ž mnist æ•°æ®é›†å¼€å§‹ï¼Œå¹¶åˆ›å»ºä¸€ä¸ªç®€å•çš„ CNN æ¨¡åž‹:

```py
import tensorflow as tf

mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
validation_data = x_test, y_test

model = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(10, activation='softmax')
])

```

æˆ‘ä»¬å°†åœ¨ keras ä¸­åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰æŒ‡æ ‡ã€å¤šç±»åˆ« **f1 åˆ†æ•°:**

```py
def recall(y_true, y_pred):
    y_true = K.ones_like(y_true) 
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    all_positives = K.sum(K.round(K.clip(y_true, 0, 1)))

    recall = true_positives / (all_positives + K.epsilon())
    return recall

def precision(y_true, y_pred):
    y_true = K.ones_like(y_true) 
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))

    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    return precision

def f1_score(y_true, y_pred):
    precision = precision_m(y_true, y_pred)
    recall = recall_m(y_true, y_pred)
    return 2*((precision*recall)/(precision+recall+K.epsilon()))

```

æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªå®šåˆ¶çš„ tf.keras åº¦é‡:**multiclasstruepoints**ç¡®åˆ‡åœ°è¯´:

```py
class MulticlassTruePositives(tf.keras.metrics.Metric):
    def __init__(self, name='multiclass_true_positives', **kwargs):
        super(MulticlassTruePositives, self).__init__(name=name, **kwargs)
        self.true_positives = self.add_weight(name='tp', initializer='zeros')

    def update_state(self, y_true, y_pred, sample_weight=None):
        y_pred = tf.reshape(tf.argmax(y_pred, axis=1), shape=(-1, 1))
        values = tf.cast(y_true, 'int32') == tf.cast(y_pred, 'int32')
        values = tf.cast(values, 'float32')
        if sample_weight is not None:
            sample_weight = tf.cast(sample_weight, 'float32')
            values = tf.multiply(values, sample_weight)
        self.true_positives.assign_add(tf.reduce_sum(values))

    def result(self):
        return self.true_positives

    def reset_states(self):

        self.true_positives.assign(0.)
```

æˆ‘ä»¬å°†**ç”¨æˆ‘ä»¬çš„æŒ‡æ ‡ç¼–è¯‘ keras æ¨¡åž‹**:

```py
import keras

model.compile(optimizer='sgd',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy',
                       keras.metrics.categorical_accuracy,
                       f1_score, 
                       recall_score, 
                       precision_score,
                       tf.keras.metrics.TopKCategoricalAccuracy(k=5),
                       MulticlassTruePositives()])
```

æˆ‘ä»¬å°†å®žçŽ° keras **å›žè°ƒï¼Œå®ƒå°† ROC æ›²çº¿å’Œæ··æ·†çŸ©é˜µ**ç»˜åˆ¶åˆ°ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­:

```py
import os

from keras.callbacks import Callback
import matplotlib.pyplot as plt
import numpy as np
from scikitplot.metrics import plot_confusion_matrix, plot_roc

class PerformanceVisualizationCallback(Callback):
    def __init__(self, model, validation_data, image_dir):
        super().__init__()
        self.model = model
        self.validation_data = validation_data

        os.makedirs(image_dir, exist_ok=True)
        self.image_dir = image_dir

    def on_epoch_end(self, epoch, logs={}):
        y_pred = np.asarray(self.model.predict(self.validation_data[0]))
        y_true = self.validation_data[1]             
        y_pred_class = np.argmax(y_pred, axis=1)

        fig, ax = plt.subplots(figsize=(16,12))
        plot_confusion_matrix(y_true, y_pred_class, ax=ax)
        fig.savefig(os.path.join(self.image_dir, f'confusion_matrix_epoch_{epoch}'))

        fig, ax = plt.subplots(figsize=(16,12))
        plot_roc(y_true, y_pred, ax=ax)
        fig.savefig(os.path.join(self.image_dir, f'roc_curve_epoch_{epoch}'))

performance_viz_cbk = PerformanceVisualizationCallback(
                                       model=model,
                                       validation_data=validation_data,
                                       image_dir='perorfmance_charts')
```

æˆ‘ä»¬å°†**è¿›è¡ŒåŸ¹è®­**å¹¶ç›‘æŽ§è¡¨çŽ°:

```py
history = model.fit(x=x_train,
                    y=y_train,
                    epochs=5,
                    validation_data=validation_data,
                    callbacks=[performance_viz_cbk])
```

æˆ‘ä»¬å°†**å¯è§†åŒ–æ¥è‡ª keras åŽ†å²å¯¹è±¡çš„æŒ‡æ ‡:**

```py
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

```

æˆ‘ä»¬å°†åœ¨ TensorBoard æˆ– Neptune ç­‰å·¥å…·ä¸­ç›‘æŽ§å’ŒæŽ¢ç´¢æ‚¨çš„å®žéªŒã€‚

## æµ·çŽ‹æ˜Ÿ

```py
run = neptune.init(
        project='YOUR_WORKSAPCE/YOUR_PROJECT_NAME',
        api_token='YOUR_API_TOKEN')

neptune_cbk = NeptuneCallback(run=run, base_namespace='metrics')
history = model.fit(..., callbacks=[neptune_cbk])

```

å¦‚æžœæ‚¨æ„Ÿå…´è¶£ï¼Œè¯·æŸ¥çœ‹æ­¤[æ–‡æ¡£](https://web.archive.org/web/20220926093651/https://docs.neptune.ai/integrations-and-supported-tools/model-training/tensorflow-keras)å’Œç¤ºä¾‹[å®žéªŒè¿è¡Œ](https://web.archive.org/web/20220926093651/https://app.neptune.ai/o/common/org/tf-keras-integration/e/TFK-35541/dashboard/metrics-b11ccc73-9ac7-4126-be1a-cf9a3a4f9b74):

ðŸ‘‰äº†è§£æ›´å¤šå…³äºŽ Neptune ä¸Ž Keras çš„æ•´åˆã€‚

## å¼ é‡æ¿

æ‚¨åªéœ€è¦**æ·»åŠ å¦ä¸€ä¸ªå›žè°ƒæˆ–è€…ä¿®æ”¹æ‚¨ä¹‹å‰å·²ç»**åˆ›å»ºçš„å›žè°ƒ:

```py
from  tf.keras.callbacks import TensorBoard

tensorboard_cbk = TensorBoard(log_dir="logs/training-example/")

history = model.fit(..., callbacks=[performance_viz_cbk, 
                                    tensorboard_cbk])
```

ä½¿ç”¨ TensorBoardï¼Œæ‚¨éœ€è¦å¯åŠ¨æœ¬åœ°æœåŠ¡å™¨å¹¶åœ¨æµè§ˆå™¨ä¸­æµè§ˆæ‚¨çš„è·‘æ­¥è®°å½•ã€‚

```py
tensorboard --logdir logs/training-example/
```

## æœ€åŽçš„æƒ³æ³•

å¸Œæœ›è¿™ç¯‡æ–‡ç« èƒ½ç»™ä½ ä¸€äº› keras ä¸­æ¨¡åž‹è¯„ä¼°æŠ€æœ¯çš„èƒŒæ™¯çŸ¥è¯†ã€‚

æˆ‘ä»¬æ¶µç›–äº†:

*   keras å’Œ tf.keras ä¸­çš„å†…ç½®æ–¹æ³•ï¼Œ
*   å®žçŽ°æ‚¨è‡ªå·±çš„å®šåˆ¶æŒ‡æ ‡ï¼Œ
*   å¦‚ä½•åœ¨æ¨¡åž‹è®­ç»ƒæ—¶å¯è§†åŒ–è‡ªå®šä¹‰æ€§èƒ½å›¾è¡¨ã€‚

æ¬²äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹ Keras çŸ¥è¯†åº“å’Œå¼ é‡æµåº¦é‡æ–‡æ¡£ã€‚

å¿«ä¹è®­ç»ƒï¼

### å¾·é‡Œå…‹Â·å§†ç»´è’‚

Derrick Mwiti æ˜¯ä¸€åæ•°æ®ç§‘å­¦å®¶ï¼Œä»–å¯¹åˆ†äº«çŸ¥è¯†å……æ»¡çƒ­æƒ…ã€‚ä»–æ˜¯æ•°æ®ç§‘å­¦ç¤¾åŒºçš„çƒ­å¿ƒè´¡çŒ®è€…ï¼Œä¾‹å¦‚ Heartbeatã€Towards Data Scienceã€Datacampã€Neptune AIã€KDnuggets ç­‰åšå®¢ã€‚ä»–çš„å†…å®¹åœ¨ç½‘ä¸Šè¢«æµè§ˆäº†è¶…è¿‡ä¸€ç™¾ä¸‡æ¬¡ã€‚å¾·é‡Œå…‹ä¹Ÿæ˜¯ä¸€åä½œå®¶å’Œåœ¨çº¿æ•™å¸ˆã€‚ä»–è¿˜åŸ¹è®­å„ç§æœºæž„å¹¶ä¸Žä¹‹åˆä½œï¼Œä»¥å®žæ–½æ•°æ®ç§‘å­¦è§£å†³æ–¹æ¡ˆå¹¶æå‡å…¶å‘˜å·¥çš„æŠ€èƒ½ã€‚ä½ å¯èƒ½æƒ³çœ‹çœ‹ä»–åœ¨ Python è¯¾ç¨‹ä¸­å®Œæ•´çš„æ•°æ®ç§‘å­¦å’Œæœºå™¨å­¦ä¹ è®­ç»ƒè¥ã€‚

* * *

**é˜…è¯»ä¸‹ä¸€ç¯‡**

## å¦‚ä½•åœ¨æ‚¨çš„é¡¹ç›®ä¸­è·Ÿè¸ªæœºå™¨å­¦ä¹ æ¨¡åž‹æŒ‡æ ‡

3 åˆ†é’Ÿé˜…è¯»| Jakub Czakon |å‘å¸ƒäºŽ 2020 å¹´ 6 æœˆ 22 æ—¥

è·Ÿè¸ªæœºå™¨å­¦ä¹ æ¨¡åž‹çš„è¯„ä¼°æŒ‡æ ‡è‡³å…³é‡è¦ï¼Œä»¥ä¾¿:

*   äº†è§£æ‚¨çš„æ¨¡åž‹åšå¾—å¦‚ä½•
*   èƒ½å¤Ÿå°†å®ƒä¸Žä»¥å‰çš„åŸºçº¿å’Œæƒ³æ³•è¿›è¡Œæ¯”è¾ƒ
*   äº†è§£ä½ ç¦»é¡¹ç›®ç›®æ ‡æœ‰å¤šè¿œ

â€œå¦‚æžœä½ ä¸è¡¡é‡å®ƒï¼Œä½ å°±ä¸èƒ½æ”¹è¿›å®ƒã€‚â€

ä½†æ˜¯ä½ åº”è¯¥è·Ÿè¸ªä»€ä¹ˆå‘¢ï¼Ÿ

æˆ‘ä»Žæ¥æ²¡æœ‰å‘çŽ°è‡ªå·±åœ¨è¿™æ ·çš„æƒ…å†µä¸‹ï¼Œæˆ‘è®¤ä¸ºæˆ‘å·²ç»ä¸ºæˆ‘çš„æœºå™¨å­¦ä¹ å®žéªŒè®°å½•äº†å¤ªå¤šçš„æŒ‡æ ‡ã€‚

æ­¤å¤–ï¼Œåœ¨çŽ°å®žä¸–ç•Œçš„é¡¹ç›®ä¸­ï¼Œæ‚¨æ‰€å…³å¿ƒçš„æŒ‡æ ‡å¯èƒ½ä¼šç”±äºŽæ–°çš„å‘çŽ°æˆ–ä¸æ–­å˜åŒ–çš„è§„èŒƒè€Œæ”¹å˜ï¼Œå› æ­¤è®°å½•æ›´å¤šçš„æŒ‡æ ‡å®žé™…ä¸Šå¯ä»¥åœ¨å°†æ¥ä¸ºæ‚¨èŠ‚çœä¸€äº›æ—¶é—´å’Œéº»çƒ¦ã€‚

ä¸ç®¡æ€Žæ ·ï¼Œæˆ‘çš„å»ºè®®æ˜¯:

â€œè®°å½•æ¯”ä½ è®¤ä¸ºéœ€è¦çš„æ›´å¤šçš„æŒ‡æ ‡ã€‚â€

å¥½å§ï¼Œä½†æ˜¯ä½ å…·ä½“æ˜¯æ€Žä¹ˆåšçš„å‘¢ï¼Ÿ

### è·Ÿè¸ªå•ä¸€æ•°å­—çš„æŒ‡æ ‡

åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œæ‚¨å¯ä»¥ä¸ºæœºå™¨å­¦ä¹ æ¨¡åž‹çš„æ€§èƒ½åˆ†é…ä¸€ä¸ªæ•°å€¼ã€‚æ‚¨å¯ä»¥è®¡ç®—ä¿ç•™éªŒè¯é›†çš„å‡†ç¡®åº¦ã€AUC æˆ–å¹³å‡ç²¾åº¦ï¼Œå¹¶å°†å…¶ç”¨ä½œæ¨¡åž‹è¯„ä¼°æŒ‡æ ‡ã€‚

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨åº”è¯¥è·Ÿè¸ªæ¯æ¬¡å®žéªŒè¿è¡Œçš„æ‰€æœ‰è¿™äº›å€¼ã€‚

[Continue reading ->](/web/20220926093651/https://neptune.ai/blog/how-to-track-machine-learning-model-metrics)

* * *