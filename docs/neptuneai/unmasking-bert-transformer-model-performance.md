# æ­å¼€ BERT çš„é¢çº±:å˜å‹å™¨æ¨¡å‹æ€§èƒ½çš„å…³é”®

> åŸæ–‡ï¼š<https://web.archive.org/web/https://neptune.ai/blog/unmasking-bert-transformer-model-performance>

å¦‚æœä½ æ­£åœ¨é˜…è¯»è¿™ç¯‡æ–‡ç« ï¼Œä½ å¯èƒ½çŸ¥é“åƒ BERT è¿™æ ·çš„æ·±åº¦å­¦ä¹ å˜å‹å™¨æ¨¡å‹ã€‚ä»–ä»¬æ­£åœ¨å½»åº•æ”¹å˜æˆ‘ä»¬å¤„ç†è‡ªç„¶è¯­è¨€çš„æ–¹å¼ã€‚

ğŸ’¡*å¦‚æœä½ ä¸çŸ¥é“ï¼Œæˆ‘ä»¬åœ¨[ä¸Šä¸€ç¯‡æ–‡ç« ä¸­å†™äº†å…³äº BERT å’Œ Transformer æ¶æ„çš„å†å²å’Œå½±å“ã€‚](/web/20220928192338/https://neptune.ai/blog/bert-and-the-transformer-architecture-reshaping-the-ai-landscape)*

![Transformer models ](img/be0887515eeabfa9fc7993a8e74d77cc.png)

*Examples of some Transformer models available from HuggingFace (the largest open-source library of Deep Learning NLP models). You can see that most of them are based on BERT in some way.*

è¿™äº›å‹å·æ€§èƒ½éå¸¸å¥½ã€‚ä½†æ˜¯ä¸ºä»€ä¹ˆå‘¢ï¼Ÿä¸ºä»€ä¹ˆä¸å…¶ä»–å˜å‹å™¨å‹å·ç›¸æ¯”ï¼ŒBERT çš„æ€§èƒ½å¦‚æ­¤å‡ºè‰²ï¼Ÿ

æœ‰äººå¯èƒ½ä¼šè¯´ä¼¯ç‰¹æ²¡ä»€ä¹ˆç‰¹åˆ«çš„ã€‚å˜å‹å™¨æ¶æ„æ˜¯æˆ‘ä»¬è¿‘å¹´æ¥çœ‹åˆ°çš„æœ€å…ˆè¿›(SOTA)æ”¹è¿›çš„ç‹¬ç‰¹åŸå› ã€‚

è¿™æ˜¯ä»¤äººå›°æƒ‘çš„ï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦ç¡®åˆ‡åœ°çŸ¥é“ BERT çš„å“ªäº›éƒ¨åˆ†å€¼å¾—åœ¨æœªæ¥çš„æ¨¡å‹ä¸­å¤åˆ¶ã€‚å¦åˆ™ï¼Œæˆ‘ä»¬æœ€ç»ˆå¯èƒ½ä¼šç”Ÿäº§å‡ºä¸å¿…è¦çš„åºå¤§çš„æ¨¡ä»¿æ¨¡å‹ï¼Œå¹¶ä¸”åŒ…å«æ— åŠ©äºæ”¹è¿›çš„å±‚æ¬¡å’ŒåŸ¹è®­ç›®æ ‡ã€‚

![Masking BERT](img/5b77837c2c49186d2cfa2389ade5eb20.png)

*Is it masking that makes BERT so special? How does it work? Hopefully, this slide will make more sense after you read this post. Source:* [*Stanford slides by Jacob Devlin*](https://web.archive.org/web/20220928192338/https://nlp.stanford.edu/seminar/details/jdevlin.pdf)

ä¸ºäº†æ¾„æ¸…è¿™ä¸€å›°æƒ‘ï¼Œæˆ‘ä»¬å°†çœ‹çœ‹è¿™ä¸€é¢†åŸŸçš„ä¸€äº›æœ€æ–°ç ”ç©¶ï¼Œå¹¶æå‡º:

1.  **æ©è”½æ˜¯å…³é”®**:â€œæ©è”½â€æ˜¯åŸ¹è®­ç›®æ ‡ï¼Œæˆ‘ä»¬å°†å¤§éƒ¨åˆ†æˆåŠŸå½’åŠŸäº BERT å’Œç±»ä¼¼ BERT çš„æ¨¡å‹ã€‚
2.  **å±è”½éœ€è¦æ³¨æ„**:è™½ç„¶å±è”½æ˜¯åŒºåˆ« BERT ä¸å…¶ä»–æ¨¡å‹çš„å…³é”®å› ç´ ï¼Œä½†å®ƒæ˜¯å»ºç«‹åœ¨é€šè¿‡[å˜å‹å™¨æ¶æ„](https://web.archive.org/web/20220928192338/https://arxiv.org/pdf/1706.03762.pdf)å¼•å…¥çš„æ³¨æ„æœºåˆ¶ä¹‹ä¸Šçš„ã€‚
3.  **æˆ‘ä»¬ä»ç„¶ä¸ç†è§£æ©è”½**:å°½ç®¡æ©è”½æ˜¯æœ€è¿‘ NLP SOTA ç»“æœä¸­çš„æ ¸å¿ƒå…ƒç´ ï¼Œæˆ‘ä»¬ä»ç„¶ä¸å®Œå…¨ç†è§£æ©è”½æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚æˆ‘ä»¬æ¥çœ‹çœ‹æœ€è¿‘çš„ç ”ç©¶ï¼Œè¿™äº›ç ”ç©¶è¡¨æ˜ï¼Œä»¥å‰è¢«è®¤ä¸ºå¯¹æ©è”½çš„æˆåŠŸè‡³å…³é‡è¦çš„è¯­è¨€(å¦‚å•è¯æ’åº)çš„*å¥æ³•æ–¹é¢å¹¶ä¸é‡è¦ã€‚è¿™æå‡ºäº†ä¸€ä¸ªé‡è¦çš„é—®é¢˜ï¼Œå³æˆ‘ä»¬è®¤ä¸ºè¿™äº›æ¨¡å‹åœ¨å­¦ä¹ ä»€ä¹ˆè¯­è¨€ã€‚*
4.  æˆ‘ä»¬å¯èƒ½éœ€è¦é‡æ–°è¯„ä¼°æˆ‘ä»¬æ˜¯å¦‚ä½•å­¦ä¹ è¯­è¨€çš„:äººç±»å¦‚ä½•å­¦ä¹ è¯­è¨€æ˜¯ä¸€ä¸ªæŒç»­äº‰è®ºçš„è¯é¢˜ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬è®¤ä¸ºï¼Œå½“äººç±»å­¦ä¹ å•è¯çš„å«ä¹‰æ—¶ï¼Œä»–ä»¬æ‰€åšçš„ä¸ä»…ä»…æ˜¯ç®€å•çš„å…±ç°å’Œæ¨¡å¼åŒ¹é…ã€‚ä½†æ˜¯ï¼Œå¦‚æœè¿™å®é™…ä¸Šæ˜¯åƒ BERT è¿™æ ·çš„æ¨¡å‹å­¦ä¹ è¯­è¨€çš„æ–¹å¼ï¼Œå¦‚æœå®ƒä»¬å¯ä»¥è¾¾åˆ°æˆ–æ¥è¿‘äººç±»çš„æ°´å¹³ï¼Œé‚£ä¹ˆï¼Œäººç±»åªæ˜¯ä»¥åŒæ ·çš„æ–¹å¼å­¦ä¹ å’Œç†è§£è¯­è¨€çš„æœ‰æœºç»Ÿè®¡æ¨ç†å¼•æ“å—ï¼Ÿä¹Ÿè®¸æˆ‘ä»¬éœ€è¦é‡æ–°å®¡è§†æˆ‘ä»¬è®¤ä¸ºäººç±»æ˜¯å¦‚ä½•ä»è¯­è¨€ä¸­å­¦ä¹ æ„ä¹‰çš„ã€‚

ä¼¼ä¹å¾ˆæ˜æ˜¾ï¼Œç›®å‰ï¼Œåœ¨ NLP æ·±åº¦å­¦ä¹ çš„æŠ€æœ¯ç”Ÿå‘½å‘¨æœŸä¸­ï¼Œå®è·µè¿œè¿œé¢†å…ˆäºç†è®ºã€‚æˆ‘ä»¬ä½¿ç”¨äº†ä¸€äº›æ–¹æ³•ï¼Œæ¯”å¦‚å±è”½ï¼Œè¿™äº›æ–¹æ³•çœ‹èµ·æ¥å¾ˆæœ‰æ•ˆï¼Œæˆ‘ä»¬ç¨å¾®æ‘†å¼„ä¸€ä¸‹æ•°å­—ï¼Œæ•ˆæœä¼šå¥½ä¸€ç‚¹æˆ–è€…å·®ä¸€ç‚¹ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬æ— æ³•å®Œå…¨è§£é‡Šä¸ºä»€ä¹ˆä¼šå‘ç”Ÿè¿™ç§æƒ…å†µï¼

æœ‰äº›äººå¯èƒ½ä¼šè§‰å¾—è¿™ä»¤äººæ²®ä¸§å’Œå¤±æœ›ã€‚å¦‚æœæˆ‘ä»¬ä¸èƒ½è§£é‡Šå®ƒï¼Œé‚£ä¹ˆæˆ‘ä»¬å¦‚ä½•ä½¿ç”¨å®ƒï¼Ÿ

ä¹Ÿè®¸æˆ‘ä»¬ä¸éœ€è¦å®Œå…¨è§£é‡Šè¿™äº›æ¨¡å‹ã€‚æˆ‘ä»¬ä»ç„¶å¯ä»¥æ”¾å¿ƒåœ°åœ¨ç”Ÿäº§å’Œé‡è¦çš„å•†ä¸šåº”ç”¨ä¸­ä½¿ç”¨å®ƒä»¬ï¼ŒåŒæ—¶åŠªåŠ›æ›´å¥½åœ°ç†è§£å®ƒä»¬çš„å†…éƒ¨å·¥ä½œæ–¹å¼ã€‚

## è¡¨ç¤ºå’Œå­¦ä¹ :å˜å‹å™¨æ¨¡å‹å¦‚ä½•å­¦ä¹ ä¸Šä¸‹æ–‡

![BERT_context](img/33620727e2f866b1233a1f307e7a4369.png)

*Nearly all transformer models learn some form of context which helps improve their performance in NLP tasks. The question is why do models like BERT appear to learn more from context than other models? Is this due to their learning objective? Source:* [*Demystifying BERT*](https://web.archive.org/web/20220928192338/https://www.analyticsvidhya.com/blog/2019/09/demystifying-bert-groundbreaking-nlp-framework/)

ä¼¯ç‰¹ä¸æ˜¯é•‡ä¸Šå”¯ä¸€çš„è¡¨æ¼”ï¼Œæˆ–è€…åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ˜¯è¡—ä¸Šå”¯ä¸€çš„æœ¨å¶ï¼è¿˜æœ‰å…¶ä»–æ¨¡å‹ä½¿ç”¨ Transformer æ¶æ„ï¼Œè€Œæ²¡æœ‰å­¦ä¹ ç›®æ ‡ï¼Œå¦‚å±è”½(ä¸è¦æ‹…å¿ƒï¼Œæˆ‘ä»¬å°†å¾ˆå¿«å®šä¹‰æ‰€æœ‰è¿™äº›æœ¯è¯­)ã€‚æˆ‘ä»¬å¯ä»¥çœ‹çœ‹è¿™äº›æ¨¡å‹æ˜¯å¦‚ä½•æ‰§è¡Œçš„ï¼Œä»¥åŠè¿™äº›æ¨¡å‹å†…éƒ¨å‘ç”Ÿäº†ä»€ä¹ˆï¼Œä»¥æ¯”è¾ƒå’Œå¯¹æ¯” BERTs å­¦ä¹ ç›®æ ‡åœ¨æ¥è‡ªå…¶è¾“å…¥çš„å­¦ä¹ ç¯å¢ƒä¸­çš„æ‰§è¡Œæƒ…å†µã€‚

ä¸Šä¸‹æ–‡æ˜¯å°† BERT å’Œå…¶ä»–å˜å½¢é‡‘åˆšæ¨¡å‹(å¦‚ GPT-3)ä¸ä»¥å‰çš„æ¨¡å‹(å¦‚ [Word2Vec](https://web.archive.org/web/20220928192338/https://arxiv.org/pdf/1301.3781.pdf) )åŒºåˆ†å¼€æ¥çš„åŸå› ï¼Œä»¥å‰çš„æ¨¡å‹åªçŸ¥é“ä¸€ä¸ªå•è¯çš„ä¸€ç§â€œæ„æ€â€ã€‚ä»è¿™ä¸ªæ„ä¹‰ä¸Šè¯´ï¼ŒWord2Vec äº§ç”Ÿé™æ€å®šä¹‰(æˆ–åµŒå…¥ï¼Œå®ƒä»¬åªæ˜¯è¡¨ç¤ºæœ‰é—®é¢˜çš„å•è¯çš„å‘é‡)ï¼Œå› ä¸ºå®ƒä»¬åªæœ‰ä¸€ä¸ªå«ä¹‰ï¼Œä¸ä¼šæ ¹æ®ä½¿ç”¨å®ƒçš„ä¸Šä¸‹æ–‡è€Œæ”¹å˜ã€‚

è¿™æœ‰æ˜æ˜¾çš„å±€é™æ€§ã€‚ä½ ç›®å‰æ­£åœ¨é˜…è¯»ä¸€ä¸ªå…³äºä¼¯ç‰¹çš„*å¸–å­ï¼Œä½†æ˜¯ä½ ä¹Ÿå¯ä»¥åœ¨ ***å¸–å­*** ä¸­æ¥æ”¶é‚®ä»¶ï¼Œæˆ–è€…åœ¨ä½ çš„èŠ±å›­é‡Œè´´ä¸€ä¸ªæœ¨åˆ¶ ***å¸–å­*** ç­‰ç­‰ã€‚â€œ ***post*** â€çš„æ¯ä¸€æ¬¡ä½¿ç”¨éƒ½æœ‰éå¸¸ä¸åŒçš„å«ä¹‰ã€‚è¿™ä¸ªé—®é¢˜é˜»æ­¢äº†åƒ Word2Vec è¿™æ ·çš„æ¨¡å‹åŒ¹é…åƒ BERT (â€¦ *æˆ–è€…ä¹Ÿè®¸ä¸åŒ¹é…ï¼Ÿç¨åæˆ‘ä»¬å°†è®¨è®º BERT æ˜¯å¦ä»…ä»…æ˜¯å¸¦æœ‰åŠ¨æ€ä¸Šä¸‹æ–‡çš„ Word2Vec çš„å¤§è§„æ¨¡æ”¾å¤§ç‰ˆæœ¬*ã€‚*

 *åœ¨è¿™ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹çœ‹ä¸‰ç§ä¸åŒç±»å‹çš„æ¨¡å‹ï¼Œå®ƒä»¬å…·æœ‰ä¸‰ç§ä¸åŒçš„å­¦ä¹ ç›®æ ‡ï¼Œå¹¶è¡¨æ˜è¿™äº›å­¦ä¹ ç›®æ ‡æ”¹å˜äº†å…³äºæ„ä¹‰å’Œä¸Šä¸‹æ–‡çš„ä¿¡æ¯åœ¨å®ƒä»¬çš„ç¥ç»ç½‘ç»œå±‚ä¹‹é—´ä¼ é€’çš„æ–¹å¼ã€‚è¿™å°†å¯¼è‡´æˆ‘ä»¬å£°ç§°ï¼Œå½“æ©è”½è¢«ç”¨ä½œå­¦ä¹ ç›®æ ‡æ—¶ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆåƒ BERT è¿™æ ·çš„æ¨¡å‹æ¯”éæ©è”½æ›¿ä»£æ–¹æ¡ˆæ›´å¥½åœ°å­¦ä¹ ä¸Šä¸‹æ–‡çš„åŸå› ã€‚æœ¬å¸–ä¸­æˆ‘ä»¬è¦çœ‹çš„æ¨¡å‹æ˜¯:

1.  **æœºå™¨ç¿»è¯‘(MT)æ¨¡å‹**:è¿™æ˜¯ç¬¬ä¸€æ‰¹å±•ç¤º Transformer æ¶æ„åœ¨ç¥ç»æœºå™¨ç¿»è¯‘(NMT)ç­‰åº”ç”¨ä¸­äº§ç”Ÿé‡å¤§æ”¹è¿›æ½œåŠ›çš„æ¨¡å‹ã€‚
2.  **è¯­è¨€æ¨¡å‹(LM)** : LMs å¦‚ç±» GPT æ¨¡å‹ï¼Œä»¥åŠå®ƒä»¬çš„é€’å½’ç¥ç»ç½‘ç»œ(RNN)å‰èº«ï¼Œé€šè¿‡é¢„æµ‹åºåˆ—ä¸­çš„ä¸‹ä¸€ä¸ªå•è¯æ¥å­¦ä¹ ã€‚
3.  æ©è”½è¯­è¨€æ¨¡å‹(MLM) :åƒä¼¯ç‰¹è¿™æ ·çš„ MLM ä½¿ç”¨äº†ä¸€ç§å«åšæ©è”½çš„æ–¹æ³•ï¼Œä»–ä»¬è¯•å›¾é¢„æµ‹æ–‡æœ¬åºåˆ—ä¸­çš„ä¸€ä¸ªéšæœºå•è¯ã€‚è¿™å¯¹è¿™äº›æ¨¡å‹çš„å·¥ä½œæ–¹å¼æœ‰ç€éå¸¸ä¸åŒçš„å½±å“ï¼Œæˆ‘ä»¬å¾ˆå¿«å°±ä¼šè°ˆåˆ°è¿™ä¸€ç‚¹ã€‚

## è¡¨ç°:å˜å‹å™¨æ¨¡å‹å¦‚ä½•ç›¸ä¼¼

![Transformers representation learning](img/de03f73b281131589e69efd5049027d1.png)

*From a high level, we can think of the Transformer models as composed of two main â€œpartsâ€; one where they represent the text, and the other where they learn from the text. Source: Author*

æ‰€æœ‰å˜å‹å™¨æ¨¡å‹åœ¨å…¶ç¥ç»ç½‘ç»œè®¾è®¡ä¸­å…±äº«ä¸€ä¸ª**é€šç”¨æ–¹æ³•ã€‚æˆ‘ä»¬å¯ä»¥è®¤ä¸ºè¿™ç§å¸¸è§çš„æ–¹æ³•æœ‰ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ã€‚å°½ç®¡æ‰€æœ‰è¿™äº›ç½‘ç»œä¹‹é—´å­˜åœ¨è®¸å¤šç»†å¾®å·®åˆ«ï¼Œä½†æˆ‘ä»¬å¯ä»¥ä»é«˜å±‚æ¬¡ä¸Šå°†å®ƒä»¬è§†ä¸ºåœ¨æ–¹æ³•ä¸Šæœ‰äº›ç›¸ä¼¼ã€‚è¿™äº›ç½‘ç»œçš„ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†æ˜¯:**

1.  **è¡¨ç¤º**:è¿™æ˜¯æ¨¡å‹æ¥å—æ–‡æœ¬è¾“å…¥å¹¶å°†å…¶è¡¨ç¤ºä¸ºæˆ‘ä»¬ç§°ä¹‹ä¸ºåµŒå…¥çš„å‘é‡çš„åœ°æ–¹ã€‚ç½‘ç»œçš„è¡¨ç¤ºéƒ¨åˆ†å°†æ–‡æœ¬ä¿¡æ¯ç¼–ç æˆç½‘ç»œå¯ä»¥â€œè¯»å–â€æˆ–å¤„ç†çš„æ ¼å¼ã€‚è¿™åŒ…æ‹¬å¯¹å•è¯åœ¨å¥å­ä¸­çš„ä½ç½®ä»¥åŠå®ƒä¸å¥å­ä¸­å…¶ä»–å•è¯çš„å…³ç³»è¿›è¡Œç¼–ç ã€‚
    åœ¨ã€Šå˜å½¢é‡‘åˆšã€‹ä¸­ï¼Œè¿™ç§ä¿¡æ¯ç¼–ç æ˜¯é€šè¿‡â€œ*æ³¨æ„*â€æœºåˆ¶å®ç°çš„(æ³¨æ„æœºåˆ¶çš„ç»†èŠ‚è¶…å‡ºäº†æœ¬æ–‡çš„èŒƒå›´ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œè¯¦ç»†è®¨è®ºäº†ï¼›æˆ–è€…ï¼Œè¿™ç¯‡[å¸–å­](https://web.archive.org/web/20220928192338/https://towardsdatascience.com/illustrated-self-attention-2d627e33b20a)å¾ˆå¥½åœ°è¯´æ˜äº†æ³¨æ„åŠ›åœ¨åŸºäºå˜å‹å™¨çš„ç½‘ç»œä¸­æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚å¯¹äºè¿™ç¯‡æ–‡ç« ï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“çš„æ˜¯ï¼Œæ³¨æ„åŠ›æ˜¯ä¸€ç§å°†å…³äºæˆ‘ä»¬è¾“å…¥æ–‡æœ¬çš„ä¿¡æ¯ç¼–ç ä¸ºçŸ¢é‡æ ¼å¼çš„æœºåˆ¶â€”â€”ä¸€ç§åµŒå…¥â€”â€”æˆ‘ä»¬çš„ç¥ç»ç½‘ç»œå¯ä»¥å¤„ç†ã€‚
2.  **å­¦ä¹ **:ä¸€æ—¦ Transformer æ¨¡å‹å¯ä»¥å°†æ–‡æœ¬è¡¨ç¤ºä¸ºåµŒå…¥ï¼Œæˆ‘ä»¬å°±å¯ä»¥åˆ›å»ºä¸€ä¸ªå­¦ä¹ ç›®æ ‡ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿä»æ–‡æœ¬ä¸­â€œå­¦ä¹ â€ã€‚æˆ‘ä»¬å¸Œæœ›å­¦ä¹ ç›®æ ‡å°†ä½¿è¿™äº›æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ è¯¸å¦‚å¥æ³•ç»“æ„ã€è¯­ä¹‰å’Œä¸Šä¸‹æ–‡ä¹‹ç±»çš„ä¸œè¥¿ï¼Œè¿™å°†ä½¿å®ƒä»¬èƒ½å¤Ÿåœ¨å¹¿æ³›çš„è¯­è¨€ä»»åŠ¡ä¸­è¡¨ç°è‰¯å¥½ã€‚å­¦ä¹ ç›®æ ‡è§„å®šäº†è¿™äº›æ¨¡å‹å¯ä»¥ä»å®ƒä»¬çš„è®­ç»ƒæ•°æ®ä¸­å­¦ä¹ ä»€ä¹ˆï¼Œå› ä¸ºå®ƒæ§åˆ¶äº†ä¿¡æ¯å¦‚ä½•é€šè¿‡å®ƒä»¬çš„ç½‘ç»œæµåŠ¨ã€‚

## å­¦ä¹ :å˜å‹å™¨å‹å·æœ‰ä½•ä¸åŒ

![Transformers learning diagram](img/b000ac4988fa4b5ac650a8aa16a93afd.png)

*Each Transformer model can have its learning objective which defines how information flows through the network and how it learns from the input. Source: Author*

æ¯ä¸ªå˜å‹å™¨æ¨¡å‹å¯ä»¥åˆ›å»ºå…¶å­¦ä¹ å¯¹è±¡ï¼Œè¯¥å­¦ä¹ å¯¹è±¡å°†æ¥è‡ªç½‘ç»œè¡¨ç¤ºéƒ¨åˆ†çš„è¾“å‡ºä½œä¸ºå…¶è¾“å…¥ã€‚è¡¨ç¤ºéƒ¨åˆ†ç”±è®°å·èµ‹äºˆå™¨å’Œæ³¨æ„å±‚ç»„æˆï¼Œå®ƒä»¬æ¥å—è¾“å…¥å¹¶å°†å…¶è½¬åŒ–ä¸ºåµŒå…¥ï¼Œä»¥çŸ¢é‡æ ¼å¼è¡¨ç¤ºè¾“å…¥æ–‡æœ¬ã€‚

å­¦ä¹ ç›®æ ‡çš„é€‰æ‹©å¯¹å˜å‹å™¨æ¨¡å‹è‡³å…³é‡è¦ï¼Œå› ä¸ºè¿™ç§é€‰æ‹©-

1.  **å®šä¹‰ç½‘ç»œå¦‚ä½•å¤„ç†è¾“å…¥**:æ ¹æ®å­¦ä¹ ç›®æ ‡ï¼Œå˜æ¢å™¨æ¨¡å‹å°†ä¸€æ¬¡å¤„ç†ä¸€ä¸ªä»¤ç‰Œ(å•è¯)çš„è¾“å…¥ï¼Œå³å®ƒå°†ä¸èƒ½â€œé¢„æµ‹â€ä¸‹ä¸€ä¸ªå•è¯ï¼›æˆ–è€…å®ƒå°†èƒ½å¤Ÿâ€œåŒå‘â€å¤„ç†æ–‡æœ¬ï¼Œå¹¶åœ¨å­¦ä¹ æ—¶è®¿é—®è¿‡å»å’Œæœªæ¥çš„æ ‡è®°ã€‚
2.  **å®šä¹‰ä¿¡æ¯å¦‚ä½•åœ¨ç½‘ç»œä¸­æµåŠ¨**:å­¦ä¹ å¯¹è±¡çš„ç›®æ ‡å°†å®šä¹‰ä¿¡æ¯å¦‚ä½•åœ¨ç½‘ç»œä¸­æµåŠ¨ã€‚è¿™ä¸€ç‚¹å¾ˆé‡è¦ï¼Œå› ä¸ºåƒ Transformer æˆ– BERT æ¨¡å‹è¿™æ ·çš„æ·±åº¦ç¥ç»ç½‘ç»œç”±å¤šå±‚ç»„æˆï¼Œæ¯ä¸€å±‚éƒ½å»ºç«‹åœ¨å‰ä¸€å±‚çš„è¾“å‡ºä¹‹ä¸Šã€‚
    ç†æƒ³æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ›æ¯ä¸€å±‚éƒ½åœ¨è¾“å…¥ä¸­æ·»åŠ ä¿¡æ¯ï¼Œå¹¶å»ºç«‹åœ¨å‰ä¸€å±‚æ‰€å­¦çš„åŸºç¡€ä¸Šã€‚è¿™æ ·ï¼Œç†è®ºä¸Šï¼Œéšç€ä¿¡æ¯ä»è¾ƒä½æ°´å¹³ä¼ é€’åˆ°è¾ƒé«˜æ°´å¹³ï¼Œæ·±åº¦ç¥ç»ç½‘ç»œåº”è¯¥å»ºç«‹æ›´å¤æ‚å’Œæ›´é«˜æ°´å¹³çš„çŸ¥è¯†ã€‚å­¦ä¹ å¯¹è±¡å°†å®šä¹‰è¿™ä¸ªä¿¡æ¯æµã€‚
    ä¾‹å¦‚ï¼Œåœ¨å›¾åƒå¤„ç†ä¸­ä½¿ç”¨çš„å·ç§¯ç¥ç»ç½‘ç»œ(CNN)ä¸­ï¼Œç½‘ç»œçš„ä½å±‚å­¦ä¹ ä¸€èˆ¬ç»†èŠ‚ï¼Œå¦‚å½¢çŠ¶çš„è¾¹ç•Œå’Œè½®å»“ã€‚ç„¶åï¼Œæ›´é«˜å±‚å­¦ä¹ æ›´å¤šç»†å¾®çš„ç»†èŠ‚ï¼Œå¦‚é¢éƒ¨ç‰¹å¾å’ŒåŒºåˆ†åŒä¸€ç±»å‹å›¾åƒçš„ç»†èŠ‚æ–¹é¢ã€‚å¦‚æœå›¾åƒæ˜¯ä¸€åªçŒ«ï¼Œè¾ƒä½å±‚å°†è¯†åˆ«çŒ«çš„ä¸€èˆ¬æ ¼å¼ï¼Œå¹¶èƒ½å¤Ÿå°†å…¶ä¸ç‹—æˆ–äººåŒºåˆ†å¼€æ¥ï¼Œè¾ƒé«˜å±‚å°†èƒ½å¤ŸåŒºåˆ†ä¸åŒç±»å‹çš„çŒ«ã€‚ç†æƒ³æƒ…å†µä¸‹(æˆ‘ä»¬ä¸ç¡®å®šï¼Œä½†ä¼¼ä¹æœ‰å¯èƒ½)ï¼Œæˆ‘ä»¬å¸Œæœ›è¯­è¨€æ¨¡å‹ä»¥ç±»ä¼¼çš„æ–¹å¼ä»æ–‡æœ¬ä¸­å­¦ä¹ ä¿¡æ¯ï¼Œä»¥ä¾¿æ›´é«˜å±‚ç†è§£è¯­ä¹‰å’Œå¥æ³•ç‰¹å¾ã€‚

æˆ‘ä»¬åœ¨è¿™ç¯‡æ–‡ç« ä¸­çœ‹åˆ°çš„ä¸‰ç§æ¨¡å‹æœ‰ä¸åŒçš„å­¦ä¹ ç›®æ ‡:

1.  **æœºå™¨ç¿»è¯‘(MT)å­¦ä¹ ç›®æ ‡** : MT æ¨¡å‹è·å–è¾“å…¥æ–‡æœ¬ï¼Œå¹¶å°è¯•é¢„æµ‹ç›®æ ‡å¥å­ä¸­çš„å•è¯ã€‚è¾“å…¥å¥å­å¯ä»¥æ˜¯è‹±è¯­ï¼Œè€Œç›®æ ‡å¥å­æ˜¯è¯¥å¥å­çš„æ³•è¯­ç¿»è¯‘ã€‚ML æ¨¡å‹ä¸è¿™é‡Œè®¨è®ºçš„å…¶ä»–æ¨¡å‹ç•¥æœ‰ä¸åŒï¼Œå› ä¸ºè¡¨ç¤ºå±‚åµŒå…¥ä¸ç”¨äºç›´æ¥é¢„æµ‹è¾“å‡ºã€‚ç›¸åï¼Œå¯¹äº MT æ¨¡å‹ï¼Œè¡¨ç¤ºå±‚çš„è¾“å‡ºè¢«ä¼ é€’ç»™è§£ç å™¨ï¼Œè§£ç å™¨å°†åµŒå…¥å†…å®¹è½¬æ¢å›ç›®æ ‡è¯­è¨€ã€‚å‡ºäºæˆ‘ä»¬çš„ç›®çš„ï¼Œæˆ‘ä»¬ä»ç„¶å¯ä»¥ç”¨ä¸å…¶ä»–æ¨¡å‹ç›¸åŒçš„æ–¹å¼æ¥è€ƒè™‘å®ƒï¼Œå³å­¦ä¹ ç›®æ ‡è¯•å›¾é¢„æµ‹ç»™å®šä¸åŒæºè¯­è¨€è¾“å…¥çš„ç›®æ ‡å¥å­çš„å•è¯ã€‚
2.  **è¯­è¨€æ¨¡å‹(LM)å­¦ä¹ ç›®æ ‡**:åƒ GPT è¿™æ ·çš„ LM æ¨¡å‹è¯•å›¾æ ¹æ®è¾“å…¥å¥å­ä¸­çš„å‰å‡ ä¸ªå•è¯æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ã€‚å› æ­¤ï¼Œå­¦ä¹ ç›®æ ‡åªèƒ½è®¿é—®å¥å­ä¸­è¿‡å»çš„å•è¯ï¼Œå³å®ƒä¸èƒ½â€œæœŸå¾…â€å¥å­ä¸­çš„ä¸‹ä¸€ä¸ªå•è¯æ¥å¸®åŠ©å®ƒé¢„æµ‹å½“å‰å•è¯ã€‚è¿™æ ·ï¼ŒLM æ¨¡å‹è¢«ç§°ä¸ºæ˜¯å•å‘çš„ï¼Œå› ä¸ºå®ƒåªä»è¾“å…¥å¼€å§‹åˆ°è¾“å…¥ç»“æŸâ€œè¯»å–â€æ–‡æœ¬ã€‚
3.  **å±è”½è¯­è¨€æ¨¡å‹(MLM)** : **å­¦ä¹ ç›®æ ‡** : MLMs ä¸æ˜¯é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ï¼Œè€Œæ˜¯è¯•å›¾é¢„æµ‹ä»è¾“å…¥ä¸­éšæœºé€‰æ‹©çš„â€œå±è”½â€å•è¯ã€‚è¿™æ˜¯[å®Œå½¢å¡«ç©º](https://web.archive.org/web/20220928192338/https://en.wikipedia.org/wiki/Cloze_test)çš„ä¸€ç§å½¢å¼ï¼Œè¦æ±‚å‚ä¸è€…é¢„æµ‹ä¸€ä¸ªå¥å­ä¸­éšè—çš„å•è¯ã€‚å®ƒé€šå¸¸è¢«ç”¨æ¥è¯„ä¼°ä¸€ä¸ªäººçš„è¯­è¨€èƒ½åŠ›ã€‚ç”±äºå®Œå½¢å¡«ç©ºæµ‹è¯•è¦æ±‚ç”¨æˆ·èƒ½å¤Ÿçœ‹åˆ°æ‰€æœ‰çš„æ–‡æœ¬ä»¥ç†è§£ç¼ºå¤±å•è¯çš„ä¸Šä¸‹æ–‡ï¼Œæ‰€ä»¥ MLMs éœ€è¦èƒ½å¤ŸåŒæ—¶â€œçœ‹åˆ°â€æ‰€æœ‰çš„æ–‡æœ¬ã€‚è¿™ä¸ LMs ç›¸åï¼ŒLMs åœ¨é¢„æµ‹å½“å‰å•è¯æ—¶åªçœ‹åˆ°è¿‡å»çš„å•è¯ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬è¯´ MLM æ˜¯â€œ*åŒå‘çš„*â€ï¼Œå› ä¸ºå®ƒä»¬å¯ä»¥è®¿é—®å½“å‰é¢„æµ‹å•è¯å‰åçš„å•è¯ã€‚

## æ©è”½è¯­è¨€æ¨¡å‹(MLM)çš„è¡¨ç°æ›´å¥½å—ï¼Ÿ

![Masked language models](img/849673edd4854fba57902411131a3716.png)

*Example of a person dragging words to missing spaces in a cloze test.* *Source:* [*Wikipedia*](https://web.archive.org/web/20220928192338/https://en.wikipedia.org/wiki/Cloze_test)

æˆ‘ä»¬æƒ³è¦å›ç­”çš„å…³é”®é—®é¢˜æ˜¯ï¼ŒMLM æ¨¡å‹æ˜¯å¦æ¯”å…¶ä»–æ¨¡å‹æ›´æ“…é•¿å­¦ä¹ è¯­è¨€ä¿¡æ¯ã€‚è™½ç„¶è¿™æ˜¯ä¸€ä»¶å¾ˆéš¾è¡¡é‡çš„äº‹æƒ…ï¼Œå› ä¸ºæˆ‘ä»¬é¦–å…ˆä¸çŸ¥é“äººç±»æ˜¯å¦‚ä½•å­¦ä¹ è¯­è¨€çš„ï¼Œä½†æˆ‘ä»¬å¯ä»¥é€šè¿‡è§‚å¯Ÿç½‘ç»œå„å±‚ä¹‹é—´è¾“å…¥ä¿¡æ¯çš„å˜åŒ–æ¥ä¼°è®¡å®ƒã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å…³æ³¨çš„æ˜¯:

1.  **æ¨¡å‹å¦‚ä½•å­¦ä¹ è¾“å…¥**:æœ€åˆï¼Œæ¨¡å‹éœ€è¦ç†è§£ç»™å®šçš„è¾“å…¥ã€‚å®ƒä¼šæŸ¥çœ‹å¯ç”¨çš„ä¿¡æ¯ï¼Œå¹¶åœ¨ç”Ÿæˆå­¦ä¹ ç›®æ ‡æ‰€éœ€çš„è¾“å‡ºä¹‹å‰ï¼Œå°½å¯èƒ½å¤šåœ°å°è¯•å’Œç†è§£è¾“å…¥ã€‚
2.  **æ¨¡å‹å¦‚ä½•ä½¿ç”¨è¯¥ä¿¡æ¯æ¥æ‰§è¡Œå…¶ä»»åŠ¡**:å­¦ä¹ ç›®æ ‡å®šä¹‰äº†æˆ‘ä»¬æ¨¡å‹çš„ç›®æ ‡ï¼Œå³å®ƒè¯•å›¾é¢„æµ‹ä»€ä¹ˆã€‚ä¸€æ—¦æ¨¡å‹äº†è§£äº†ä¸€äº›å¯ç”¨çš„è¾“å…¥ï¼Œå®ƒå°±å¯ä»¥å…³æ³¨å®ƒéœ€è¦ç”Ÿæˆçš„è¾“å‡ºï¼Œä»¥å°è¯•å¹¶æ»¡è¶³å­¦ä¹ ç›®æ ‡çš„è¦æ±‚ã€‚

ä¾‹å¦‚ï¼Œå‡è®¾ç»™ä½ ä¸€ä¸ªç±»ä¼¼äº*å®Œå½¢å¡«ç©ºæµ‹è¯•*çš„ä»»åŠ¡ï¼Œå¹¶è¦æ±‚ä½ é¢„æµ‹é—æ¼çš„å•è¯:

> "*è¿™æ˜¯æˆ‘çœ‹è¿‡çš„[* ***æ¼å­—*** *]å¸–å­*"

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ å¯ä»¥å…ˆè¯»å®Œæ•´ä¸ªå¥å­ï¼Œç„¶åæŠŠæ³¨æ„åŠ›é›†ä¸­åœ¨ç¼ºå¤±å•è¯çš„ä¸Šä¸‹æ–‡ä¸Šã€‚ä¸€å¼€å§‹ï¼Œä½ ä¸ä¼šå»æƒ³é‚£ä¸ªç¼ºå¤±çš„å•è¯æœ¬èº«ã€‚ä½ ä¼šçœ‹å®ƒå‰åçš„å•è¯ï¼Œå¹¶æŠŠå®ƒä»¬ä½œä¸ºé¢„æµ‹ä¸¢å¤±å•è¯çš„ä¾æ®ã€‚

ä¸€æ—¦ä½ æ€è€ƒäº†å‘¨å›´çš„å•è¯ï¼Œä½ å°±è¯•ç€å»æ€è€ƒç¼ºå¤±çš„å•è¯ã€‚ä½ ä¸ºè¿™ä¸ªè¯æƒ³å‡ºäº†ä¸€äº›å¯èƒ½çš„é€‰é¡¹ï¼Œå¹¶è€ƒè™‘å®ƒä»¬æ˜¯å¦ç¬¦åˆä¸Šä¸‹æ–‡ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä½ ä¼š(å¾ˆæ˜æ˜¾åœ°)æƒ³åˆ°åƒâ€œ*æœ€å¥½çš„*â€ã€â€œ*æœ€ä¼Ÿå¤§çš„*â€ã€â€œ*å®Œç¾çš„*â€ã€â€œ*æ°å‡ºçš„*â€ã€â€œ*æœ€å¥½çš„*â€è¿™æ ·çš„è¯ï¼Œå¹¶é€‰æ‹©å…¶ä¸­ä¸€ä¸ªä½ è®¤ä¸ºæ­£ç¡®çš„ã€‚

ä¸€äº›ç ”ç©¶äººå‘˜å·²ç»ç ”ç©¶äº†ç½‘ç»œä¹‹é—´ä¿¡æ¯å˜åŒ–çš„è¿™ä¸ªæ–¹é¢ï¼Œå¹¶è¯•å›¾ä¼°è®¡ä¸åŒå±‚ä¹‹é—´ä¸¢å¤±æˆ–è·å¾—çš„ä¿¡æ¯ã€‚ä»–ä»¬ç”¨å‡ ç§ä¸åŒçš„æ–¹æ³•æ¥åšè¿™ä»¶äº‹ã€‚ä¸€ç§æ–¹æ³•æ˜¯æŸ¥çœ‹ä¸åŒé˜¶æ®µè¾“å…¥å±‚å’Œè¾“å‡ºå±‚ä¹‹é—´è·å¾—æˆ–ä¸¢å¤±çš„ä¿¡æ¯ï¼Œå³è¾“å…¥å±‚å’Œç¬¬äºŒå±‚ä¹‹é—´çš„å·®å¼‚ã€è¾“å…¥å±‚å’Œç¬¬äº”å±‚ã€ç¬¬ n å±‚ä¹‹é—´çš„å·®å¼‚ç­‰ç­‰ã€‚

é€šè¿‡è¿™æ ·åšï¼Œä»–ä»¬è¡¨æ˜:

1.  **æœºå™¨ç¿»è¯‘åœ¨å„å±‚ä¹‹é—´å˜åŒ–è¾ƒå°**:ç”±äºæœºå™¨ç¿»è¯‘ä¸é¢„æµ‹å®Œå½¢å¡«ç©ºç±»å‹å­¦ä¹ å¯¹è±¡çš„æ ‡è®°ï¼Œå› æ­¤å®ƒåœ¨è¿ç»­å„å±‚çš„è¡¨ç¤ºä¹‹é—´å˜åŒ–è¾ƒå°ã€‚ä½ å¯ä»¥åœ¨ä¸‹å›¾ä¸­çœ‹åˆ°è¿™ä¸€ç‚¹ï¼Œå®ƒæ˜¾ç¤ºäº†å±‚ä¸å±‚ä¹‹é—´è¶Šæ¥è¶Šå°‘çš„å˜åŒ–ã€‚å®ƒè¯•å›¾ç¿»è¯‘æ•´ä¸ªå¥å­ï¼Œæ‰€ä»¥å®ƒæ²¡æœ‰æˆ‘ä»¬ä¸Šé¢æåˆ°çš„ä¸¤æ­¥ç„¦ç‚¹å˜åŒ–ï¼Œå…¶ä¸­æ¨¡å‹ç†è§£ä¸Šä¸‹æ–‡ï¼Œç„¶åé¢„æµ‹æ ‡ç­¾ã€‚
2.  **è¯­è¨€æ¨¡å‹æ˜¾ç¤ºä¼ªé€ å’Œé‡æ–°è®°å¿†çš„è¯æ®**:ç›¸æ¯”ä¹‹ä¸‹ï¼ŒLMs æ˜¾ç¤ºå‡ºæ›´å¤šçš„å±‚é—´å˜åŒ–ï¼Œå› ä¸ºå®ƒä»¬æœ€åˆä¸“æ³¨äºå‘¨å›´å•è¯çš„ä¸Šä¸‹æ–‡ï¼Œå±‚é—´çš„å·®å¼‚é€æ¸å˜å°ã€‚ç„¶åï¼Œå½“æ¨¡å‹è¯•å›¾é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯æ—¶ï¼Œæˆ‘ä»¬ä¼šçœ‹åˆ°å„å±‚ä¹‹é—´çš„è¾ƒå¤§å˜åŒ–ã€‚
3.  **æ©è”½è¯­è¨€æ¨¡å‹æ˜¾ç¤ºäº†å±‚é—´æœ€å¤§çš„å˜åŒ–**:MLM åœ¨ç»å†è¿™ä¸¤æ­¥è¿‡ç¨‹æ—¶ï¼Œæ˜¾ç¤ºäº†å±‚é—´æ›´åŠ æ˜æ˜¾çš„å˜åŒ–ã€‚æœ€åˆï¼ŒMLM ä¸¢å¼ƒæˆ–â€œä¸¢å¤±â€å®ƒç°åœ¨ä¸éœ€è¦çš„ä¿¡æ¯ï¼Œå³è¯¥æ¨¡å‹å…³æ³¨å‘¨å›´å•è¯çš„ä¸Šä¸‹æ–‡ï¼Œè€Œä¸æ˜¯å®ƒè¯•å›¾é¢„æµ‹çš„ç¼ºå¤±å•è¯ã€‚ç„¶åï¼Œå½“å®ƒå°†æ³¨æ„åŠ›è½¬ç§»åˆ°é‡æ–°è®°ä½ä¸å®ƒè¯•å›¾é¢„æµ‹çš„ä¸¢å¤±æ ‡è®°ç›¸å…³çš„ä¿¡æ¯ï¼Œå³*å­¦ä¹ ç›®æ ‡*æ—¶ï¼Œæˆ‘ä»¬çœ‹åˆ°å„å±‚ä¹‹é—´çš„è¡¨ç¤ºå‘ç”Ÿäº†å·¨å¤§å˜åŒ–ã€‚

## è¢«æ©ç›–çš„è¯­è¨€æ¨¡å‹ç§˜å¯†:ä¸Šä¸‹æ–‡ç¼–ç å’Œæ ‡è®°é‡æ„

MLMs çš„ç±»ä¼¼å®Œå½¢å¡«ç©ºçš„ä»»åŠ¡ï¼Œå³å±è”½è¾“å…¥ä¸­çš„éšæœºå•è¯ï¼Œä¼¼ä¹è¿«ä½¿å˜å‹å™¨æ¨¡å‹ç»å†ä¸¤ä¸ªéƒ¨åˆ†çš„è¿‡ç¨‹ï¼Œ[ç ”ç©¶](https://web.archive.org/web/20220928192338/https://arxiv.org/abs/1909.01380)çš„ä½œè€…æè¿°ä¸º:

1.  **ä¸Šä¸‹æ–‡ç¼–ç **:æ­£å¦‚æˆ‘ä»¬ä¹‹å‰æåˆ°çš„ï¼Œè¿™æ˜¯æ¨¡å‹è¢«è¿«å…³æ³¨å‘¨å›´å•è¯çš„ä¸Šä¸‹æ–‡ï¼Œè€Œä¸æ˜¯å­¦ä¹ ç›®æ ‡çš„ç›®çš„ã€‚MLMs ä¼¼ä¹æ¯” LMs åšå¾—æ›´å¥½ï¼Œå› ä¸ºå®ƒä»¬å¯ä»¥è®¿é—®è¾“å…¥æ–‡æœ¬ä¸­çš„æ•´ä¸ªå•è¯æ•°ç»„ï¼Œè€Œä¸åƒ LMs é‚£æ ·åªèƒ½è®¿é—®å‰é¢çš„å•è¯ã€‚ä¸ LMs æˆ– MLMs ç±»ä¼¼ï¼ŒMT æ¨¡å‹æ²¡æœ‰é¢„æµ‹è¾“å‡ºéœ€æ±‚ä»»åŠ¡çš„æ ‡ç­¾ï¼Œå› æ­¤å®ƒä»¬ç”šè‡³æ›´å¿«åœ°â€œå¿˜è®°â€ä¸æ­£åœ¨å¤„ç†çš„å½“å‰å•è¯ç›¸å…³çš„ä¿¡æ¯ã€‚
2.  **è®°å·é‡å»º** : MLMs æ˜¾ç¤ºäº†ä¸€ä¸ªæ¸…æ™°çš„ç¬¬äºŒé˜¶æ®µï¼Œå…¶ä¸­æ¨¡å‹å°†ç„¦ç‚¹ä»å­¦ä¹ ä¸Šä¸‹æ–‡è½¬ç§»åˆ°è¯•å›¾é¢„æµ‹ä¸¢å¤±æˆ–è¢«å±è”½çš„å•è¯ã€‚ä¸ºæ­¤ï¼Œå®ƒä¼šå°è¯•â€œæ¢å¤â€æˆ–â€œé‡å»ºâ€å…³äºå½“å‰è¾“å…¥ä»¤ç‰Œçš„ä¿¡æ¯ã€‚å®ƒè¿™æ ·åšæ˜¯å› ä¸ºå®ƒè¯•å›¾ç†è§£å½“å‰æ ‡è®°ä¸å¥å­ä¸­å…¶ä»–æ ‡è®°çš„ç›¸å…³ç¨‹åº¦ã€‚åœ¨ä¸Šä¸‹æ–‡ç¼–ç é˜¶æ®µï¼Œæ¨¡å‹æŸ¥çœ‹å‘¨å›´çš„å·¥ä½œï¼Œä¾‹å¦‚ï¼Œå¦‚æœå½“å‰å•è¯æ˜¯â€œ*é“¶è¡Œ*â€ï¼Œæˆ‘ä»¬å¯ä»¥é¦–å…ˆæŸ¥æ‰¾ç±»ä¼¼â€œ*é’“é±¼*â€æˆ–â€œ*é‡‘é’±*â€çš„å‘¨å›´å•è¯ï¼Œä»¥äº†è§£æˆ‘ä»¬æ‰€æŒ‡çš„æ˜¯ä»€ä¹ˆç±»å‹çš„â€œ*é“¶è¡Œ*â€ï¼Œå³ï¼Œä¸€æ¡æ²³â€œ*é“¶è¡Œ*â€æˆ–ä¸€ä¸ªé‡‘èæœºæ„ã€‚

è¯¥ç ”ç©¶ä¸­å¦ä¸€ä¸ªå®éªŒçš„ä¸‹å›¾æ›´æ¸…æ¥šåœ°æ˜¾ç¤ºäº†è¿™ä¸€ä¸¤é˜¶æ®µè¿‡ç¨‹çš„å½±å“:

åœ¨ä¸Šå›¾ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼ŒMLM å¼€å§‹é‡å»ºå…³äºå½“å‰è¾“å…¥ä»¤ç‰Œçš„ä¿¡æ¯ï¼Œè€Œ ML å’Œ LM ç»§ç»­ä¸¢å¤±ä¸è¾“å…¥ä»¤ç‰Œç›¸å…³çš„ä¿¡æ¯ï¼Œå³å®ƒä»¬æ²¡æœ‰æ˜ç¡®çš„â€œé‡å»ºâ€é˜¶æ®µã€‚

## åƒ BERT è¿™æ ·çš„å±è”½è¯­è¨€æ¨¡å‹å—ç›Šäºæœªæ¥

åƒä¸Šé¢æåˆ°çš„é‚£äº›ç ”ç©¶è¡¨æ˜ï¼ŒMLM ä¼¼ä¹æ˜¯åƒ BERT è¿™æ ·çš„å¤§å‹é¢„è®­ç»ƒæ¨¡å‹çš„æ›´å¥½é€‰æ‹©ï¼Œè¿™äº›æ¨¡å‹éœ€è¦æœ‰æ›´ä¸€èˆ¬çš„è¯­è¨€çŸ¥è¯†ï¼Œä»¥ä¾¿åœ¨ä¸‹æ¸¸ NLP ä»»åŠ¡ä¸­è¡¨ç°å¾—æ›´å¥½ã€‚

è¿™ä¼¼ä¹ä¸ MLMs å¯ä»¥è®¿é—®è¾“å…¥æ–‡æœ¬ä¸­çš„æœªæ¥ä¿¡æ¯çš„äº‹å®æœ‰å…³ï¼Œå› ä¸º Transformer æ¶æ„æä¾›äº†**åŒå‘ç‰¹æ€§**ã€‚è¿˜è®°å¾—å¼•è¨€å—ï¼Œæˆ‘ä»¬æåˆ°æ©è”½æ˜¯è‡³å…³é‡è¦çš„ï¼Œä½†å®ƒå–å†³äºæ³¨æ„åŠ›ï¼ŸTransformer æ¶æ„çš„**æ³¨æ„æœºåˆ¶**ä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨å­¦ä¹ ä¸å½“å‰è¾“å…¥ä»¤ç‰Œç›¸å…³çš„å‘¨å›´å•è¯çš„ä¸Šä¸‹æ–‡æ—¶â€œå±•æœ›â€æœªæ¥ã€‚

è¯­è¨€æ¨¡å‹ä¹Ÿå¯ä»¥ä½¿ç”¨è¿™ä¸€åŠŸèƒ½ï¼Œå› ä¸ºå®ƒä»¬ä½¿ç”¨ç›¸åŒçš„åº•å±‚æ¶æ„ï¼Œä½†æ˜¯å®ƒä»¬çš„å­¦ä¹ ç›®æ ‡çš„æ€§è´¨æ„å‘³ç€å®ƒä»¬åªæŸ¥çœ‹å¥å­ä¸­ä»¥å‰çš„å•è¯ã€‚ä»–ä»¬ä¸ä¼šâ€œé¢„æµ‹â€æ¥ä¸‹æ¥çš„å•è¯ï¼Œå› ä¸ºè¿™ä¼šç»™ç½‘ç»œè®¾è®¡å¸¦æ¥ä¸€äº›é—®é¢˜ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ¨¡å‹å¯ä»¥è®¿é—®è¾“å…¥ä¸­çš„æ‰€æœ‰æ ‡è®°ï¼Œé‚£ä¹ˆä»ç†è®ºä¸Šè®²ï¼Œå®ƒå¯ä»¥â€œæ¬ºéª—â€å¹¶æ€»æ˜¯é¢„æµ‹æ­£ç¡®çš„ä¸‹ä¸€ä¸ªå•è¯ï¼Œè€Œæ— éœ€å­¦ä¹ ä»»ä½•ä¸œè¥¿ã€‚

å› æ­¤ï¼Œåœ¨æ¨¡å‹ç®€å•æ€§å’Œå­¦ä¹ ç›®æ ‡æ”¶ç›Šä¹‹é—´æœ‰ä¸€ä¸ªæƒè¡¡ã€‚MLM ä½¿æ¨¡å‹äº†è§£æ›´å¤šå…³äºè¾“å…¥æ–‡æœ¬çš„ä¿¡æ¯ï¼Œä½†è¿™æ˜¯ä»¥æ›´å¤§çš„æ¨¡å‹å¤æ‚æ€§ä¸ºä»£ä»·çš„ã€‚

ä¾‹å¦‚ï¼ŒGPT-3 æ˜¯ä¸€ç§ LM æ¨¡å‹ï¼Œå®ƒä½¿ç”¨è½¬æ¢å™¨æ¶æ„çš„è§£ç å™¨éƒ¨åˆ†æ¥é¢„æµ‹è¾“å…¥åºåˆ—ä¸­çš„ä¸‹ä¸€ä¸ªå­—ã€‚åƒ GPT-3 è¿™æ ·çš„æ¨¡å‹å¯ä»¥é€šè¿‡åœ¨æ›´å¤§å’Œå¤šæ ·åŒ–çš„æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒæ¥è¡¥å¿å­¦ä¹ ç›®æ ‡çš„å·®å¼‚ã€‚GPT-3 çš„è¡¨ç°è¡¨æ˜ï¼Œä½ ä»ç„¶å¯ä»¥é€šè¿‡è¿™æ¡è·¯çº¿å®ç° SOTA çš„ç»“æœã€‚

ç„¶è€Œï¼Œä»ä¸Šé¢çš„ç»“æœï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ° MLM çš„å¥½å¤„ï¼Œç”±äºæ˜ç¡®çš„ä¸Šä¸‹æ–‡ç¼–ç å’Œä»¤ç‰Œé‡å»ºé˜¶æ®µã€‚å¦‚æœä½ æƒ³ä»ä½ çš„è¾“å…¥æ–‡æœ¬ä¸­å­¦ä¹ ä¸Šä¸‹æ–‡ï¼Œé‚£ä¹ˆä¼ é”€ä»æ›´å°‘çš„å†…å®¹ä¸­å­¦åˆ°æ›´å¤šã€‚è¿™ä¼¼ä¹ä¸ MLMs è®¿é—®å½“å‰è¾“å…¥ä»¤ç‰Œå‘¨å›´çš„æœªæ¥ä¸Šä¸‹æ–‡çš„èƒ½åŠ›æœ‰å…³ã€‚

è¿™ç§ç¯å¢ƒä¼˜åŠ¿æ˜¯ MLM åœ¨è®¸å¤š NLP ä»»åŠ¡ä¸­è¡¨ç°çš„å…³é”®ã€‚ä½†æ˜¯ï¼Œæœ‰äº›ä»»åŠ¡ä¸é€‚åˆè¿™ç§åŒå‘è®¿é—®ã€‚å°±åƒåœ¨ GPT X è¿™æ ·çš„æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ä¸­ï¼Œä¸»è¦ç›®æ ‡æ˜¯é¢„æµ‹æ–‡æœ¬åºåˆ—ä¸­çš„ä¸‹ä¸€ä¸ªå•è¯ã€‚è¿™äº›æ¨¡å‹å¯èƒ½é€‚åˆé€šè¿‡ LM å­¦ä¹ ç›®æ ‡è¿›è¡Œè®­ç»ƒï¼Œä»¥å¢å¼ºå®ƒä»¬åœ¨ç»™å®šè¾“å…¥ä»»åŠ¡çš„æƒ…å†µä¸‹é¢„æµ‹æœªæ¥å•è¯çš„èƒ½åŠ›ã€‚

## BERT ä¸­çš„é®ç½©æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ

åœ¨æˆ‘ä»¬ç»“æŸä¹‹å‰ï¼Œæœ‰å¿…è¦ç‰¹åˆ«äº†è§£ä¸€ä¸‹ BERT åŠå…¶å±è”½è¿‡ç¨‹å®ç°ã€‚

åœ¨å‰é¢å‡ èŠ‚ä¸­ï¼Œæˆ‘ä»¬è®¨è®ºäº†å±è”½çš„ä¸€èˆ¬æ¦‚å¿µï¼Œå³å±è”½æ‰ä¸€ä¸ªéšæœºå•è¯ã€‚å¬èµ·æ¥ç›¸å¯¹å®¹æ˜“ã€‚

ä½†æ˜¯ï¼Œå¦‚æœæ‚¨è¿‡å»æ›¾ç»ä½¿ç”¨è¿‡ Transformer æ¨¡å‹ï¼Œæ‚¨ä¼šçŸ¥é“äº‹æƒ…ä¼šå˜å¾—æ›´åŠ å¤æ‚ã€‚BERT æ©è”½å®æ–½æœ‰ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†:

1.  **å±è”½ 15%çš„è¾“å…¥æ ‡è®°**:BERT ä¸­çš„å±è”½ä¸åªæ˜¯å±è”½ä¸€ä¸ªæ ‡è®°ã€‚ç›¸åï¼Œå®ƒéšæœºé€‰æ‹© 15%çš„è¾“å…¥æ ‡è®°å¹¶å±è”½å®ƒä»¬ã€‚15%æ˜¯é€šè¿‡è¯•é”™æ³•é€‰æ‹©çš„ã€‚å¦‚æœä½ å±è”½äº†æ›´å¤šçš„ä¿¡æ¯ï¼Œé‚£ä¹ˆæ¨¡å‹å°±å¾ˆéš¾ä»è¾“å…¥ä¸­å­¦ä¹ ï¼Œå› ä¸ºéšè—äº†å¤ªå¤šçš„ä¿¡æ¯ã€‚å¦‚æœæ‚¨ä½¿ç”¨å°‘äº 15%,å¯èƒ½éœ€è¦æ›´é•¿çš„æ—¶é—´å’Œæ›´å¤šçš„æ•°æ®æ¥å­¦ä¹ è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡ï¼Œå› ä¸ºæ¨¡å‹å¯èƒ½æ›´å®¹æ˜“é¢„æµ‹ä¸¢å¤±çš„ä»¤ç‰Œã€‚
2.  **å±è”½è®°å·ï¼Œæ­£ç¡®è®°å·ï¼Œæˆ–é”™è¯¯è®°å·**:è¿™å°±æ˜¯å¼€å§‹å˜å¾—æœ‰ç‚¹å¥‡æ€ªçš„åœ°æ–¹ï¼åœ¨é€‰æ‹©äº†æˆ‘ä»¬æƒ³è¦å±è”½çš„ä»¤ç‰Œä¹‹åï¼Œæˆ‘ä»¬éœ€è¦å†³å®šæˆ‘ä»¬æ˜¯å¦çœŸçš„æƒ³è¦å±è”½å®ƒä»¬ã€‚æˆ‘ä»¬æœ€ç»ˆä¸ä¼šå±è”½æ‰æˆ‘ä»¬è¯´è¿‡çš„æ‰€æœ‰ä»¤ç‰Œã€‚ç›¸åï¼Œæˆ‘ä»¬æœ‰å¦ä¸€ä¸ªéšæœºé€‰æ‹©è¿‡ç¨‹(æˆ‘ä»¬å°†åœ¨ä¸‹é¢è®¨è®º),æˆ‘ä»¬é€‰æ‹©æ·»åŠ ä¸€ä¸ªéšè—å•è¯çš„æ©ç æ ‡è®°ï¼Œæˆ–è€…ç”¨éšæœºé€‰æ‹©çš„ä¸åŒå•è¯æ›¿æ¢è¯¥æ ‡è®°ï¼Œæˆ–è€…ç”¨æˆ‘ä»¬æœ€åˆæ‰“ç®—æ©ç çš„æ­£ç¡®å•è¯æ›¿æ¢è¯¥æ ‡è®°ã€‚å¬èµ·æ¥å¾ˆå¥‡æ€ªï¼Œå¯¹å§ï¼Ÿç¡®å®æ˜¯ï¼Œä¸‹é¢æˆ‘ä»¬ä¼šå°½é‡æ¾„æ¸…ã€‚

## æˆ´å£ç½©è¿˜æ˜¯ä¸æˆ´å£ç½©ï¼Ÿ

ä¸€æ—¦æˆ‘ä»¬é€‰æ‹©äº†è¦å±è”½çš„ 15%çš„è¾“å…¥æ ‡è®°ï¼Œæˆ‘ä»¬å°±éœ€è¦å†³å®šæ˜¯å¦è¦å±è”½è¿™äº›æ ‡è®°ã€‚ä»–ä»¬åœ¨ BERT ä¸­çš„å·¥ä½œå¦‚ä¸‹:

1.  **80%æ›¿æ¢ä¸º[MASK]æ ‡è®°**:å¯¹äº 80%çš„é€‰å®šè¾“å…¥ï¼Œæ ‡è®°è¢«æ›¿æ¢ä¸º[MASK]æ ‡è®°ï¼Œç±»ä¼¼äºå‰é¢æåˆ°çš„ç»å…¸å®Œå½¢å¡«ç©ºæµ‹è¯•ã€‚
2.  **10%æ›¿æ¢ä¸ºä¸æ­£ç¡®çš„å•è¯**:å¯¹äº 10%çš„æ‰€é€‰è¾“å…¥ï¼Œä»¤ç‰Œè¢«å¦ä¸€ä¸ªéšæœºé€‰æ‹©çš„å•è¯æ›¿æ¢ï¼Œè¯¥å•è¯çš„å”¯ä¸€è¦æ±‚æ˜¯ä¸æ‰€é€‰ä»¤ç‰Œä¸åŒã€‚
3.  **10%æ›¿æ¢ä¸ºæ­£ç¡®çš„å•è¯**:å‰©ä½™ 10%çš„æ—¶é—´ï¼Œæ‰€é€‰ä»¤ç‰Œç®€å•åœ°æ›¿æ¢ä¸ºæ­£ç¡®çš„ä»¤ç‰Œã€‚

ä¼¯ç‰¹è®ºæ–‡çš„ä½œè€…æŒ‡å‡ºï¼Œè¿™äº›ä¸åŒæ¯”ç‡çš„é€‰æ‹©æœ‰äº›æ­¦æ–­ï¼Œæ˜¯åœ¨åå¤è¯•éªŒçš„è¿‡ç¨‹ä¸­é€‰æ‹©çš„ã€‚ç„¶è€Œï¼Œè¿™èƒŒåçš„æƒ³æ³•ä¼¼ä¹ä¸:

1.  **å¦‚æœä½ ä¸€ç›´ä½¿ç”¨æ©ç æ ‡è®°**:ä»…ä»…ä½¿ç”¨æ©ç æ ‡è®°å¯¼è‡´æ¨¡å‹å¾ˆå°‘äº†è§£å‘¨å›´å•è¯çš„ä¸Šä¸‹æ–‡ã€‚è¿™ä¼¼ä¹æ˜¯å› ä¸ºæ¨¡å‹çŸ¥é“å®ƒå¯ä»¥â€œå¿˜è®°â€å…³äºå‘¨å›´å•è¯çš„æ‰€æœ‰ä¿¡æ¯ï¼Œè€Œåªå…³æ³¨ç›®æ ‡å•è¯ã€‚è¿™ç±»ä¼¼äºç±»ä¼¼ LM çš„æ–¹æ³•ï¼Œæ„å‘³ç€ MLM æ²¡æœ‰åˆ›å»ºæˆ‘ä»¬ä¹‹å‰çœ‹åˆ°çš„æ¸…æ™°çš„ä¸¤é˜¶æ®µã€ä¸Šä¸‹æ–‡ç¼–ç å’Œä»¤ç‰Œé‡å»ºä¿¡æ¯æµï¼Œè¿™å¯¹äº MLMs ä¸­çœ‹åˆ°çš„æ”¹è¿›å­¦ä¹ éå¸¸é‡è¦ã€‚
2.  **å¦‚æœä½ ä½¿ç”¨æ©ç æ ‡è®°å’Œæ­£ç¡®çš„å•è¯**:ä¸ºäº†è§£å†³è¿™ä¸ªç¼ºç‚¹ï¼Œä½ å¯ä»¥åœ¨ 80%çš„æ—¶å€™ä½¿ç”¨æ©ç æ ‡è®°ï¼Œç„¶ååœ¨ 20%çš„æ—¶å€™ç”¨æ­£ç¡®çš„å•è¯æ›¿æ¢æ ‡è®°ã€‚ä½†æ˜¯æœ‰ä¸€ä¸ªé—®é¢˜ã€‚æ¨¡å‹å°†çŸ¥é“å½“æ©ç ä¸å­˜åœ¨æ—¶ï¼Œé‚£ä¹ˆå•è¯æ˜¯æ­£ç¡®çš„ï¼Œå¹¶ä¸”å®ƒä¸éœ€è¦å­¦ä¹ ä»»ä½•ä¸œè¥¿ï¼Œåªè¦ä¿æŒå½“å‰å•è¯ï¼Œå› ä¸ºå®ƒæ˜¯æ­£ç¡®çš„ã€‚æ¢å¥è¯è¯´ï¼Œè¯¥æ¨¡å‹å¯ä»¥â€œæ¬ºéª—â€è€Œä»€ä¹ˆä¹Ÿå­¦ä¸åˆ°ï¼Œå› ä¸ºå®ƒçŸ¥é“éå±è”½ä»¤ç‰Œæ€»æ˜¯æ­£ç¡®çš„ã€‚
3.  **å¦‚æœæ‚¨ä½¿ç”¨äº†æ©ç æ ‡è®°å’Œé”™è¯¯çš„å•è¯**:æˆ–è€…ï¼Œå¦‚æœæ‚¨åªæ˜¯ä¸€ç›´ä½¿ç”¨é”™è¯¯çš„æ ‡è®°ï¼Œé‚£ä¹ˆå½“æ©ç æ²¡æœ‰å‡ºç°æ—¶ï¼Œæ¨¡å‹å°†çŸ¥é“æ‰€é€‰çš„æ ‡è®°æ˜¯é”™è¯¯çš„æ ‡è®°ï¼Œå¹¶ä¸”å®ƒä¼šå°†å…¶è§†ä¸ºå¦ä¸€ä¸ªæ©ç ï¼Œå³æ‚¨å¯èƒ½ä¼šé‡åˆ°ä¸ä¸Šè¿°ç›¸åŒçš„é—®é¢˜ã€‚

ç»“æœæ˜¯ï¼Œç†æƒ³çš„ 80/10/10 åˆ†å‰²è¿«ä½¿ BERT äº†è§£è¾“å…¥ä¸­æ‰€æœ‰ä»¤ç‰Œçš„æ›´å¤šä¿¡æ¯ï¼Œè€Œä¸ä»…ä»…æ˜¯å½“å‰çš„è¾“å…¥ä»¤ç‰Œã€‚æˆ–è€…æ­£å¦‚[ä½œè€…æŒ‡å‡ºçš„](https://web.archive.org/web/20220928192338/https://arxiv.org/pdf/1810.04805.pdf)ã€*è¿™ä¸ªè¿‡ç¨‹çš„ä¼˜ç‚¹æ˜¯å˜æ¢å™¨ç¼–ç å™¨ä¸çŸ¥é“å®ƒå°†è¢«è¦æ±‚é¢„æµ‹å“ªäº›å•è¯æˆ–è€…å“ªäº›å•è¯å·²ç»è¢«éšæœºå•è¯æ›¿æ¢ï¼Œå› æ­¤å®ƒè¢«è¿«ä¿æŒæ¯ä¸ªè¾“å…¥æ ‡è®°çš„åˆ†å¸ƒå¼ä¸Šä¸‹æ–‡è¡¨ç¤ºã€‚*

## å…³äºæ©è”½çš„æœ€æ–°ç ”ç©¶ï¼Ÿ

åˆ«æ‹…å¿ƒï¼Œæˆ‘å†™è¿™ç¯‡æ–‡ç« çš„æ—¶å€™æ²¡æœ‰ä¸­é£ã€‚è¿™ä¸€èŠ‚çš„æ ‡é¢˜æ˜¯æ•…æ„å¼„ä¹±çš„ï¼Œä»¥è¡¨æ˜è¯åºå¯¹æˆ‘ä»¬ç†è§£è¯­è¨€çš„é‡è¦æ€§ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆ[å•è¯è¢‹ TF-IDF](https://web.archive.org/web/20220928192338/https://www.analyticsvidhya.com/blog/2020/02/quick-introduction-bag-of-words-bow-tf-idf/) æ¨¡å‹åœ¨ä¸€äº› NLP ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ã€‚ä»–ä»¬ä¸ä¿æŒè¾“å…¥å¥å­ä¸­çš„è¯åºï¼Œæ‰€ä»¥å½“è¾“å…¥å¥å­çš„é¡ºåºå¯¹æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡å¾ˆé‡è¦æ—¶ï¼Œä»–ä»¬æœ€ç»ˆä¼šå¤±å»ä¸€äº›æ„ä¹‰ã€‚

åƒ BERT è¿™æ ·çš„ MLM è¢«è®¤ä¸ºä¿ç•™äº†è¾“å…¥æ–‡æœ¬ä¸­å•è¯çš„é¡ºåºå’Œä½ç½®ã€‚è¿™ç»å¸¸è¢«è®¤ä¸ºæ˜¯ä»–ä»¬æ€§èƒ½æé«˜çš„åŸå› ã€‚åŒæ ·ï¼Œç±»ä¼¼å®Œå½¢å¡«ç©ºçš„ä»»åŠ¡è¢«è®¤ä¸ºè¿«ä½¿è¿™äº›æ¨¡å‹å­¦ä¹ è¯­è¨€çš„å¥æ³•å’Œè¯­ä¹‰æ–¹é¢ã€‚è¿™ä¸ Word2Vec ç­‰æ¨¡å‹å½¢æˆå¯¹æ¯”ï¼Œword 2 vec ä»…ä»å¤§é‡æ–‡æœ¬çš„åˆ†å¸ƒå±æ€§ä¸­å­¦ä¹ è¯­ä¹‰ã€‚

ä¸¤ç¯‡æ–°çš„ç ”ç©¶è®ºæ–‡å¯¹æ©è”½å’Œ MLMs ç»™äºˆäº†æ›´å¤šçš„å…³æ³¨ï¼Œå¹¶è¡¨æ˜æˆ‘ä»¬ä»ç„¶æ²¡æœ‰å®Œå…¨ç†è§£è¿™ä¸€æ–°å­¦ä¹ ç›®æ ‡çš„æ‰€æœ‰ç»†å¾®å·®åˆ«å’Œå¤æ‚æ€§:

1.  **æ©è”½è¯­è¨€å»ºæ¨¡å’Œåˆ†å¸ƒå‡è®¾:è¯­åºå¯¹ Little æ¥è¯´å¾ˆé‡è¦**:è¿™ç¯‡[è®ºæ–‡](https://web.archive.org/web/20220928192338/https://arxiv.org/pdf/2104.06644.pdf)å£°ç§°å•è¯çš„è¯­åºå¯¹ MLMs æ¥è¯´å¹¶ä¸é‡è¦ã€‚ä»–ä»¬é€šè¿‡éšæœºæ”¹å˜è¾“å…¥çš„å¥å­æ¥åšåˆ°è¿™ä¸€ç‚¹ï¼Œå¹¶è¡¨æ˜è¿™å¯¹ä¸€ç³»åˆ— NLP ä»»åŠ¡çš„æ•´ä½“æ€§èƒ½å½±å“æœ‰é™ã€‚ä»–ä»¬è®¤ä¸º MLMs æ€§èƒ½æé«˜çš„åŸå› å¯èƒ½æ˜¯:
    1.  **æ„é€ ç³Ÿç³•çš„ NLP è¯„ä¼°æ¡†æ¶**:è¿™äº›æ¨¡å‹çš„æµ‹è¯•å’Œè¯„ä¼°æ–¹å¼å¯¹äºè¿™äº›æ¨¡å‹æ¥è¯´å¯èƒ½è¿‡äºç®€å•ã€‚å› æ­¤ï¼Œç»“æœä¸èƒ½åæ˜ æ¨¡å‹åœ¨è¯­è¨€ä»»åŠ¡ä¸­çš„å®é™…èƒ½åŠ›ã€‚ç›¸åï¼Œä½œè€…å£°ç§°è¿™äº›è¯„ä¼°æ¡†æ¶éœ€è¦æ”¹è¿›ï¼Œä»¥è·Ÿä¸Š BERT ç­‰å˜å‹å™¨æ¨¡å‹çš„æ€§èƒ½ã€‚æˆ‘ä»¬åœ¨[æ—©å…ˆçš„å¸–å­](/web/20220928192338/https://neptune.ai/blog/ai-limits-can-deep-learning-models-like-bert-ever-understand-language)ä¸­è°ˆåˆ°å˜å‹å™¨æ¨¡å‹çš„æ½œåœ¨æé™æ—¶ä¹Ÿæåˆ°äº†è¿™ä¸€ç‚¹ã€‚
    2.  **MLMs å¯¹é«˜é˜¶å•è¯å…±ç°ç»Ÿè®¡å»ºæ¨¡çš„èƒ½åŠ›**:è¯¥è®ºæ–‡å£°ç§° BERT è¡¨ç°å¦‚æ­¤ä¹‹å¥½å®Œå…¨æ˜¯å› ä¸ºå®ƒèƒ½å¤Ÿä»å…±ç°æ•°æ®ä¸­å­¦ä¹ ã€‚æ©è”½å’Œæ³¨æ„åŠ›åªæ˜¯è®© BERT æ¯” Word2Vec è¿™æ ·çš„æ¨¡å‹å­¦åˆ°æ›´å¤šçš„ä¿¡æ¯ã€‚
2.  **å…³äºæ©è”½è¯­è¨€å»ºæ¨¡çš„å½’çº³åå·®:ä»ç»Ÿè®¡åˆ°å¥æ³•ä¾èµ–**ï¼›è¿™ç¯‡[è®ºæ–‡](https://web.archive.org/web/20220928192338/https://arxiv.org/pdf/2104.05694.pdf)èšç„¦äº MLMs çš„å®Œå½¢å¡«ç©ºä»»åŠ¡æ–¹é¢å¹¶å£°ç§°:
    1.  MLMs close ä»»åŠ¡ä¸æ˜¯çœŸæ­£çš„ close ä»»åŠ¡:å› ä¸º MLMs éšæœºé€‰æ‹©è¦å±è”½çš„å•è¯ï¼Œæ‰€ä»¥å®ƒä¸æ˜¯ä¸€ä¸ªç›‘ç£å¼å®Œå½¢å¡«ç©ºæµ‹è¯•ã€‚åœ¨å®Œå½¢å¡«ç©ºæµ‹è¯•ä¸­ï¼Œé€šå¸¸é€‰æ‹©ç¼ºå¤±çš„å•è¯ï¼Œä»¥ç¡®ä¿é—®é¢˜è¦æ±‚å‚ä¸è€…äº†è§£è¯¥è¯­è¨€çš„å¥æ³•æ€§è´¨ã€‚éšæœºé€‰æ‹©è¿™äº›ç¼ºå¤±çš„å•è¯æ„å‘³ç€ä¸€äº›å¸¸è§çš„æˆ–æ— æ„ä¹‰çš„å•è¯ï¼Œå¦‚â€œ*è¿™ä¸ª*â€ã€â€œ*é‚£ä¸ª*â€ã€â€œ*é‚£ä¸ª*â€ç­‰å¯ä»¥è¢«é€‰æ‹©ç”¨äºå®Œå½¢å¡«ç©ºã€‚æ ¹æ®ä»»åŠ¡çš„ä¸åŒï¼Œè¿™äº›å•è¯åœ¨å¼ºè¿«æ¨¡å¼å­¦ä¹ å¯¹è¯¥ä»»åŠ¡æœ‰æ„ä¹‰çš„ä¸œè¥¿æ—¶å¯èƒ½æ²¡æœ‰ç”¨ã€‚
    2.  MLMs ä¸ç›´æ¥å­¦ä¹ å¥æ³•:äººä»¬è®¤ä¸ºç±»ä¼¼å®Œå½¢å¡«ç©ºçš„æµ‹è¯•è¿«ä½¿æ¨¡å‹å­¦ä¹ å…³äºè¯­è¨€å¥æ³•ç»“æ„çš„ä¿¡æ¯ã€‚ç„¶è€Œï¼Œè¯¥è®ºæ–‡å£°ç§°è¡¨æ˜ï¼Œç›¸åï¼ŒMLM å­¦ä¹ æ ‡è®°ä¹‹é—´çš„ç›´æ¥ç»Ÿè®¡ä¾èµ–æ€§ï¼Œä½†è¿™ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿé—´æ¥å­¦ä¹ è¯­æ³•ã€‚ä»¥å‰äººä»¬è®¤ä¸ºä»…ä»…ä»ç»Ÿè®¡æ¨æ–­ä¸­å­¦ä¹ å¥æ³•æ˜¯ä¸å¯èƒ½çš„ã€‚è¿™ç¯‡è®ºæ–‡å£°ç§°ï¼Œä¼ é”€ç¡®å®è¡¨æ˜è¿™æ˜¯å¯èƒ½çš„

## æ‘˜è¦

æ€»è€Œè¨€ä¹‹ï¼Œè®©æˆ‘ä»¬é‡æ¸©ä¸€ä¸‹æˆ‘ä»¬åœ¨å¼•è¨€ä¸­æåˆ°çš„æœ€åˆçš„å››ç‚¹:

1.  **æ©è”½æ˜¯ BERTs æˆåŠŸçš„å…³é”®**:æˆ‘ä»¬çœ‹åˆ°ç ”ç©¶è¡¨æ˜æ©è”½ä½œä¸ºä¸€ä¸ªå­¦ä¹ ç›®æ ‡å¦‚ä½•æ”¹å˜åƒ BERT è¿™æ ·çš„æ·±åº¦å­¦ä¹ å˜å‹å™¨ç¥ç»ç½‘ç»œä¸­çš„ä¿¡æ¯æµã€‚è¿™ç§å˜åŒ–åˆ›å»ºäº†ä¸€ä¸ªä¸¤é˜¶æ®µå­¦ä¹ è¿‡ç¨‹ï¼Œå…¶ä¸­æ¨¡å‹é¦–å…ˆæ‰§è¡Œ*ä¸Šä¸‹æ–‡ç¼–ç *æ¥å­¦ä¹ å½“å‰è¾“å…¥å•è¯å‘¨å›´çš„å•è¯ã€‚ç„¶åå®ƒæ‰§è¡Œ*è®°å·é‡å»º*ï¼Œè¯•å›¾é¢„æµ‹é€šè¿‡ç±»ä¼¼å®Œå½¢å¡«ç©ºçš„ MLM æµ‹è¯•é€‰æ‹©çš„è¾“å‡ºå•è¯ã€‚è¿™ç§ä¸¤é˜¶æ®µè¿‡ç¨‹çš„æ€§è´¨ä¼¼ä¹å°† MLMs ä¸ LMs å’Œ MT ç­‰å…¶ä»–æ–¹æ³•åŒºåˆ†å¼€æ¥ã€‚
2.  **å±è”½éœ€è¦æ³¨æ„**:è™½ç„¶å±è”½ä½¿ BERT è¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»ç„¶éœ€è¦ Transformer æ¶æ„æ¥å®ç°ã€‚Transformer ç½‘ç»œä½¿ç”¨æ³¨æ„åŠ›æ¥åŒå‘å¤„ç†æ–‡æœ¬ï¼Œè¿™æ„å‘³ç€æ¨¡å‹å¯ä»¥åœ¨å½“å‰è¾“å…¥æ ‡è®°ä¹‹å‰å’Œä¹‹åæŸ¥çœ‹æ–‡æœ¬ã€‚é MLM æ²¡æœ‰å……åˆ†åˆ©ç”¨è½¬æ¢å™¨çš„è¿™ä¸€ç‰¹æ€§ï¼Œå› æ­¤åœ¨å­¦ä¹ è¯­è¨€ç‰¹æ€§çš„èƒ½åŠ›æ–¹é¢æ²¡æœ‰ä»¥åŒæ ·çš„æ–¹å¼å—ç›Šã€‚
3.  **æˆ‘ä»¬ä»ç„¶ä¸ç†è§£æ©è”½**:æˆ‘ä»¬çœ‹åˆ°æœ€è¿‘çš„ç ”ç©¶æå‡ºäº†æ›´å¤šå…³äºæ©è”½å¦‚ä½•æé«˜æ€§èƒ½çš„é—®é¢˜ï¼Œè€Œä¸æ˜¯ç­”æ¡ˆã€‚ç„¶è€Œï¼Œè¿™å¹¶ä¸æ„å‘³ç€æ©è”½ä¸èµ·ä½œç”¨ã€‚å®ƒåªæ˜¯ä»¥æˆ‘ä»¬æ²¡æœ‰æƒ³åˆ°çš„æ–¹å¼è¿ä½œã€‚äº‹å®ä¸Šï¼Œæˆ‘ä»¬è®¨è®ºçš„ä¸€ç¯‡è®ºæ–‡è¡¨æ˜ï¼Œæˆ‘ä»¬å¯èƒ½èƒ½å¤Ÿä»…ä»ç»Ÿè®¡æ¨æ–­ä¸­å­¦ä¹ é«˜çº§çŸ¥è¯†ï¼Œå¦‚è¯­è¨€å¥æ³•ã€‚ç›´åˆ°æœ€è¿‘ï¼Œæˆ‘ä»¬æ‰è®¤ä¸ºè¿™æ˜¯å¯èƒ½çš„ã€‚
4.  æˆ‘ä»¬éœ€è¦é‡æ–°è¯„ä¼°æˆ‘ä»¬å­¦ä¹ è¯­è¨€çš„æ–¹å¼å—ï¼Ÿå¦‚æœçœŸçš„æœ‰å¯èƒ½ä»åŒç°ç»Ÿè®¡è¿™æ ·ç®€å•çš„ä¸œè¥¿ä¸­å­¦ä¹ è¯­ä¹‰å’Œå¥æ³•çŸ¥è¯†ï¼Œé‚£ä¹ˆè¿™å¯¹è¯­è¨€æ„å‘³ç€ä»€ä¹ˆå‘¢ï¼Ÿå…·ä½“æ¥è¯´ï¼Œå®ƒå¯¹æˆ‘ä»¬å¦‚ä½•å­¦ä¹ è¯­è¨€æœ‰ä»€ä¹ˆçœ‹æ³•ï¼Ÿè™½ç„¶è¿™æ˜¯ä¸€ä¸ªæœ‰äº‰è®®çš„ç ”ç©¶é¢†åŸŸï¼Œä½†äººä»¬è®¤ä¸ºè¯­è¨€æ˜¯ä¸€ä¸ªå¤æ‚è€Œç‹¬ç‰¹çš„çŸ¥è¯†é¢†åŸŸï¼Œéœ€è¦ç‹¬ç‰¹çš„ç±»ä¼¼äººç±»çš„æŠ€èƒ½æ¥ç†è§£å®ƒã€‚ä½†ä¹Ÿè®¸æˆ‘ä»¬å’Œä¼¯ç‰¹è¿™æ ·çš„æ¨¡ç‰¹ä¸€æ ·ï¼Œé€šè¿‡è¯†åˆ«å¸¸è§å•è¯ä½•æ—¶ä¸€èµ·å‡ºç°æ¥å­¦ä¹ è¯­è¨€ï¼Ÿå¦‚æœæ˜¯è¿™æ ·çš„è¯ï¼Œé‚£ä¹ˆä¸ºä»€ä¹ˆæˆ‘ä»¬ä¼¼ä¹æ¯”è¿™äº›æ¨¡å‹æ›´å¿«åœ°å­¦ä¹ åƒè¯­ä¹‰è¿™æ ·çš„ä¸œè¥¿ï¼Œå¹¶ä¸”ä½¿ç”¨æ›´å°‘çš„æ•°æ®ï¼Ÿé€šè¿‡è¿™ç§æ–¹å¼ï¼Œå½“æˆ‘ä»¬åŠªåŠ›æ›´å¥½åœ°ç†è§£åƒ BERT è¿™æ ·çš„æ¨¡å‹å’Œåƒæ©è”½è¿™æ ·çš„å­¦ä¹ ç›®æ ‡æ—¶ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥æ›´å¤šåœ°äº†è§£æˆ‘ä»¬å­¦ä¹ å’Œç†è§£è¯­è¨€çš„ç‹¬ç‰¹èƒ½åŠ›ã€‚

æœ€åï¼Œæ˜¯ä¸æ˜¯æ‰€æœ‰çš„æ¨¡ç‰¹éƒ½åº”è¯¥åƒä¼¯ç‰¹ä¸€æ ·æ¥å—è’™ç‰ˆï¼Ÿä¸ NLP å’Œæœºå™¨å­¦ä¹ ä¸­çš„å¤§å¤šæ•°äº‹æƒ…ä¸€æ ·ï¼Œç­”æ¡ˆæ˜¯:

> çœ‹æƒ…å†µï¼

æˆ‘ä»¬å¯ä»¥è‡ªä¿¡åœ°è¯´ï¼Œå¤§å¤šæ•°æ¨¡å‹éƒ½å¯ä»¥é€šè¿‡ä½¿ç”¨åƒé¢„è®­ç»ƒä¸­çš„æ©è”½è¿™æ ·çš„æ–¹æ³•æ¥æ”¹è¿›ã€‚ç„¶è€Œï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¦‚æ–‡æœ¬ç”Ÿæˆï¼Œåƒæ©è”½è¿™æ ·çš„å­¦ä¹ ç›®æ ‡å¯èƒ½ä¸é€‚åˆè¯¥ä»»åŠ¡ï¼Œå› ä¸ºåœ¨è¾“å…¥ä¸­è®¿é—®æœªæ¥çš„å•è¯å¯èƒ½ä¸ç‰¹å®šä»»åŠ¡çš„ç›®æ ‡ç›¸æŠµè§¦ã€‚å¯¹äºæ›´ä¸€èˆ¬çš„æ¨¡å‹ï¼Œç›®æ ‡æ˜¯è®­ç»ƒä¸€ä¸ªå…·æœ‰ä¸€èˆ¬è¯­è¨€èƒ½åŠ›å¹¶èƒ½åœ¨å¹¿æ³›çš„ä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°è‰¯å¥½çš„æ¨¡å‹ï¼Œçœ‹èµ·æ¥è¿™äº›ç±»å‹çš„æ¨¡å‹ç¡®å®ä¼šå—ç›Šäºç±»ä¼¼æ©è”½çš„æ–¹æ³•ã€‚

## å‚è€ƒ

è¿™ç§å¯¹å˜å‹å™¨çš„ç ”ç©¶ä¸»è¦æ¥æºäºåƒ Lean Voita è¿™æ ·çš„äººçš„æƒŠäººå·¥ä½œã€‚å¥¹çš„åšå®¢æ˜¯æ‰€æœ‰å˜å½¢é‡‘åˆšèµ„æ–™çš„ä¸€ä¸ªå¾ˆå¥½çš„æ¥æºï¼Œç”šè‡³è¿˜æœ‰å¥¹æ•™çš„çš„[è¯¾ç¨‹çš„èµ„æ–™ï¼Œéå¸¸å€¼å¾—ä¸€çœ‹ã€‚åƒ Lean è¿™æ ·çš„äººè§£é‡Šè¿™äº›æ¨¡å‹å†…éƒ¨å‘ç”Ÿäº†ä»€ä¹ˆçš„å·¥ä½œå¯¹äºæé«˜æˆ‘ä»¬å¯¹åƒ BERT è¿™æ ·çš„æ¨¡å‹å¦‚ä½•å­¦ä¹ è¯­è¨€ä»»åŠ¡çš„ç†è§£æ˜¯è‡³å…³é‡è¦çš„ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ç‰¹åˆ«æåˆ°äº†å¥¹çš„å·¥ä½œ:](https://web.archive.org/web/20220928192338/https://lena-voita.github.io/nlp_course.html)

å…³äº BERT å’Œ Masking çš„æ›´å¤šç»†èŠ‚ï¼Œå€¼å¾—æŸ¥çœ‹çš„å…¶ä»–æ–‡ç« æœ‰:

### Cathal Horan

åœ¨ Intercom çš„ ML å›¢é˜Ÿå·¥ä½œï¼Œåœ¨é‚£é‡Œä»–åˆ›é€ äº†äººå·¥æ™ºèƒ½äº§å“ï¼Œå¸®åŠ©ä¼ä¸šæé«˜æ”¯æŒå®¢æˆ·å’Œä¸å®¢æˆ·æ²Ÿé€šçš„èƒ½åŠ›ã€‚ä»–å¯¹å“²å­¦å’ŒæŠ€æœ¯çš„äº¤å‰æ„Ÿå…´è¶£ï¼Œå°¤å…¶ç€è¿·äºæ·±åº¦å­¦ä¹ ç­‰æŠ€æœ¯å¦‚ä½•èƒ½å¤Ÿåˆ›å»ºæœ‰æœä¸€æ—¥å¯èƒ½ç†è§£äººç±»è¯­è¨€çš„æ¨¡å‹ã€‚ä»–æœ€è¿‘å®Œæˆäº†å•†ä¸šåˆ†æç†å­¦ç¡•å£«å­¦ä½ã€‚ä»–çš„ä¸»è¦å­¦ä½æ˜¯ç”µæ°”å’Œç”µå­å·¥ç¨‹ï¼Œä½†ä»–ä¹Ÿæ‹¥æœ‰å“²å­¦å­¦ä½å’Œç²¾ç¥åˆ†æç ”ç©¶çš„å“²å­¦ç¡•å£«å­¦ä½ã€‚

* * *

**é˜…è¯»ä¸‹ä¸€ç¯‡**

## å…³äºæ­£åœ¨é‡å¡‘äººå·¥æ™ºèƒ½æ ¼å±€çš„ BERT å’Œ Transformer æ¶æ„ï¼Œä½ éœ€è¦çŸ¥é“çš„ 10 ä»¶äº‹

25 åˆ†é’Ÿé˜…è¯»|ä½œè€… Cathal Horan |å¹´ 5 æœˆ 31 æ—¥æ›´æ–°

ç›®å‰ï¼Œå¾ˆå°‘æœ‰äººå·¥æ™ºèƒ½é¢†åŸŸæ¯” NLP æ›´ä»¤äººå…´å¥‹ã€‚è¿‘å¹´æ¥ï¼Œå¯ä»¥æ‰§è¡Œç±»ä¼¼äººç±»è¯­è¨€ä»»åŠ¡çš„è¯­è¨€æ¨¡å‹(LM)å·²ç»å‘å±•åˆ°æ¯”ä»»ä½•äººé¢„æœŸçš„æ›´å¥½ã€‚

äº‹å®ä¸Šï¼Œä»–ä»¬è¡¨ç°å¾—å¦‚æ­¤ä¹‹å¥½ï¼Œä»¥è‡³äº[äººä»¬æ€€ç–‘](https://web.archive.org/web/20220928192338/https://neptune.ai/blog/ai-limits-can-deep-learning-models-like-bert-ever-understand-language)ä»–ä»¬æ˜¯å¦è¾¾åˆ°äº†[ä¸€èˆ¬æ™ºåŠ›](https://web.archive.org/web/20220928192338/https://chatbotslife.com/is-gpt-3-the-first-artificial-general-intelligence-a7390dca155f)çš„æ°´å¹³ï¼Œæˆ–è€…æˆ‘ä»¬ç”¨æ¥æµ‹è¯•ä»–ä»¬çš„è¯„ä¼°æ ‡å‡†è·Ÿä¸ä¸Šã€‚å½“åƒè¿™æ ·çš„æŠ€æœ¯å‡ºç°æ—¶ï¼Œæ— è®ºæ˜¯ç”µåŠ›ã€é“è·¯ã€äº’è”ç½‘è¿˜æ˜¯ iPhoneï¼Œæœ‰ä¸€ç‚¹æ˜¯æ˜ç¡®çš„â€”â€”ä½ ä¸èƒ½å¿½è§†å®ƒã€‚å®ƒå°†æœ€ç»ˆå½±å“ç°ä»£ä¸–ç•Œçš„æ¯ä¸€ä¸ªéƒ¨åˆ†ã€‚

äº†è§£è¿™æ ·çš„æŠ€æœ¯å¾ˆé‡è¦ï¼Œå› ä¸ºè¿™æ ·ä½ å°±å¯ä»¥åˆ©ç”¨å®ƒä»¬ã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬æ¥å­¦ä¹ å§ï¼

æˆ‘ä»¬å°†æ¶µç›–åä¸ªæ–¹é¢ï¼Œå‘æ‚¨å±•ç¤ºè¿™é¡¹æŠ€æœ¯çš„æ¥æºã€å¼€å‘æ–¹å¼ã€å·¥ä½œåŸç†ä»¥åŠåœ¨ä¸ä¹…çš„å°†æ¥ä¼šæœ‰ä»€ä¹ˆæ ·çš„å‰æ™¯ã€‚è¿™åä»¶äº‹æ˜¯:

1.  **ä»€ä¹ˆæ˜¯ BERT å’Œå˜å‹å™¨ï¼Œä¸ºä»€ä¹ˆæˆ‘éœ€è¦äº†è§£å®ƒï¼Ÿ**åƒ BERT è¿™æ ·çš„æ¨¡å‹å·²ç»å¯¹å­¦æœ¯ç•Œå’Œå•†ä¸šç•Œäº§ç”Ÿäº†å·¨å¤§çš„å½±å“ï¼Œå› æ­¤æˆ‘ä»¬å°†æ¦‚è¿°è¿™äº›æ¨¡å‹çš„ä¸€äº›ä½¿ç”¨æ–¹æ³•ï¼Œå¹¶æ¾„æ¸…å›´ç»•å®ƒä»¬çš„ä¸€äº›æœ¯è¯­ã€‚
2.  åœ¨è¿™äº›æ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬åšäº†ä»€ä¹ˆï¼Ÿè¦äº†è§£è¿™äº›æ¨¡å‹ï¼Œé‡è¦çš„æ˜¯è¦äº†è§£è¿™ä¸€é¢†åŸŸçš„é—®é¢˜ï¼Œå¹¶äº†è§£åœ¨ BERT ç­‰æ¨¡å‹å‡ºç°ä¹‹å‰æˆ‘ä»¬æ˜¯å¦‚ä½•è§£å†³è¿™äº›é—®é¢˜çš„ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬å¯ä»¥äº†è§£ä»¥å‰æ¨¡å‹çš„å±€é™æ€§ï¼Œå¹¶æ›´å¥½åœ°ç†è§£ Transformer æ¶æ„å…³é”®è®¾è®¡æ–¹é¢èƒŒåçš„åŠ¨æœºï¼Œè¿™æ˜¯å¤§å¤šæ•° SOTA æ¨¡å‹(å¦‚ BERT)çš„åŸºç¡€ã€‚
3.  **NLPsâ€œImageNet æ—¶åˆ»ï¼›é¢„è®­ç»ƒæ¨¡å‹:**åŸæ¥æˆ‘ä»¬éƒ½æ˜¯è‡ªå·±è®­ç»ƒæ¨¡å‹ï¼Œæˆ–è€…ä½ è¦é’ˆå¯¹æŸä¸ªç‰¹å®šä»»åŠ¡ï¼Œå…¨é¢è®­ç»ƒä¸€ä¸ªæ¨¡å‹ã€‚å®ç°æ€§èƒ½å¿«é€Ÿå‘å±•çš„å…³é”®é‡Œç¨‹ç¢‘ä¹‹ä¸€æ˜¯åˆ›å»ºé¢„å…ˆè®­ç»ƒçš„æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹å¯ä»¥â€œç°æˆâ€ä½¿ç”¨ï¼Œå¹¶æ ¹æ®æ‚¨çš„å…·ä½“ä»»åŠ¡è¿›è¡Œè°ƒæ•´ï¼Œåªéœ€å¾ˆå°‘çš„åŠªåŠ›å’Œæ•°æ®ï¼Œè¿™ä¸€è¿‡ç¨‹ç§°ä¸ºè¿ç§»å­¦ä¹ ã€‚ç†è§£è¿™ä¸€ç‚¹æ˜¯ç†è§£ä¸ºä»€ä¹ˆè¿™äº›æ¨¡å‹åœ¨ä¸€ç³»åˆ— NLP ä»»åŠ¡ä¸­ä¸€ç›´è¡¨ç°è‰¯å¥½çš„å…³é”®ã€‚
4.  **äº†è§£å˜å½¢é‡‘åˆš:**ä½ å¯èƒ½å¬è¯´è¿‡ä¼¯ç‰¹å’Œ GPT-3ï¼Œä½†æ˜¯å…³äº[ç½—ä¼¯å¡”](https://web.archive.org/web/20220928192338/https://huggingface.co/transformers/model_doc/roberta.html)ã€[è‰¾ä¼¯ç‰¹](https://web.archive.org/web/20220928192338/https://huggingface.co/transformers/model_doc/albert.html)ã€ [XLNet](https://web.archive.org/web/20220928192338/https://huggingface.co/transformers/model_doc/xlnet.html) ï¼Œæˆ–è€…[é¾™å‰](https://web.archive.org/web/20220928192338/https://huggingface.co/transformers/model_doc/longformer.html)ã€[æ”¹é©è€…](https://web.archive.org/web/20220928192338/https://huggingface.co/transformers/model_doc/reformer.html)ï¼Œæˆ–è€… [T5 å˜å½¢é‡‘åˆš](https://web.archive.org/web/20220928192338/https://huggingface.co/transformers/model_doc/t5.html)å‘¢ï¼Ÿæ–°æ¨¡å‹çš„æ•°é‡çœ‹èµ·æ¥åŠ¿ä¸å¯æŒ¡ï¼Œä½†æ˜¯å¦‚æœæ‚¨ç†è§£ Transformer æ¶æ„ï¼Œæ‚¨å°†æœ‰æœºä¼šäº†è§£æ‰€æœ‰è¿™äº›æ¨¡å‹çš„å†…éƒ¨å·¥ä½œæ–¹å¼ã€‚è¿™å’Œä½ ç†è§£ RDBMS æŠ€æœ¯çš„æ—¶å€™æ˜¯ä¸€æ ·çš„ï¼Œè®©ä½ å¾ˆå¥½çš„æŒæ¡ MySQLã€PostgreSQLã€SQL Server æˆ–è€… Oracle ä¹‹ç±»çš„è½¯ä»¶ã€‚æ”¯æ’‘æ‰€æœ‰æ•°æ®åº“çš„å…³ç³»æ¨¡å‹ä¸æ”¯æ’‘æˆ‘ä»¬çš„æ¨¡å‹çš„è½¬æ¢å™¨æ¶æ„æ˜¯ä¸€æ ·çš„ã€‚æ˜ç™½äº†è¿™ä¸€ç‚¹ï¼ŒRoBERTa æˆ– XLNet å°±æˆäº†ä½¿ç”¨ MySQL æˆ– PostgreSQL çš„åŒºåˆ«ã€‚å­¦ä¹ æ¯ä¸ªæ¨¡å‹çš„ç»†å¾®å·®åˆ«ä»ç„¶éœ€è¦æ—¶é—´ï¼Œä½†æ˜¯ä½ æœ‰ä¸€ä¸ªåšå®çš„åŸºç¡€ï¼Œä½ ä¸æ˜¯ä»é›¶å¼€å§‹ã€‚
5.  **åŒå‘æ€§çš„é‡è¦æ€§**:å½“ä½ è¯»è¿™ç¯‡æ–‡ç« æ—¶ï¼Œä½ å¹¶æ²¡æœ‰ä¸¥æ ¼åœ°ä»ä¸€è¾¹è¯»åˆ°å¦ä¸€è¾¹ã€‚ä½ ä¸æ˜¯ä»ä¸€è¾¹åˆ°å¦ä¸€è¾¹ä¸€ä¸ªå­—æ¯ä¸€ä¸ªå­—æ¯åœ°è¯»è¿™ä¸ªå¥å­ã€‚ç›¸åï¼Œä½ æ­£åœ¨å‘å‰è·³è·ƒï¼Œä»ä½ ç°åœ¨æ‰€å¤„çš„ä½ç½®ä¹‹å‰çš„å•è¯å’Œå­—æ¯ä¸­å­¦ä¹ ä¸Šä¸‹æ–‡ã€‚äº‹å®è¯æ˜ï¼Œè¿™æ˜¯å˜å‹å™¨æ¶æ„çš„ä¸€ä¸ªå…³é”®ç‰¹æ€§ã€‚Transformer æ¶æ„æ”¯æŒæ¨¡å‹ä»¥åŒå‘æ–¹å¼å¤„ç†æ–‡æœ¬ï¼Œä»å¼€å§‹åˆ°ç»“æŸï¼Œä»ç»“æŸåˆ°å¼€å§‹ã€‚è¿™æ˜¯ä»¥å‰æ¨¡å‹å±€é™æ€§çš„æ ¸å¿ƒï¼Œä»¥å‰çš„æ¨¡å‹åªèƒ½ä»å¤´åˆ°å°¾å¤„ç†æ–‡æœ¬ã€‚

[Continue reading ->](/web/20220928192338/https://neptune.ai/blog/bert-and-the-transformer-architecture-reshaping-the-ai-landscape)

* * **